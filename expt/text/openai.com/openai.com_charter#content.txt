


OpenAI Charter













CloseSearch Submit Skip to main contentSite NavigationResearchOverviewIndexProductOverviewChatGPTGPT-4DALLÂ·E 2Customer storiesSafety standardsAPI data privacyPricingDevelopersOverviewDocumentationAPI referenceExamplesSafetyCompanyAboutBlogCareersCharterSecuritySearch Navigation quick links Log inSign upMenu Mobile Navigation CloseSite NavigationResearchProductDevelopersSafetyCompany Quick Links Log inSign upSearch Submit OpenAI CharterOur Charter describes the principles we use to execute on OpenAIâs mission.PublishedApril 9, 2018This document reflects the strategy weâve refined over the past two years, including feedback from many people internal and external to OpenAI. The timeline to AGI remains uncertain, but our Charter will guide us in acting in the best interests of humanity throughout its development.OpenAIâs mission is to ensure that artificial general intelligence (AGI)âby which we mean highly autonomous systems that outperform humans at most economically valuable workâbenefits all of humanity. We will attempt to directly build safe and beneficial AGI, but will also consider our mission fulfilled if our work aids others to achieve this outcome. To that end, we commit to the followingÂ principles:Broadly distributed benefitsWe commit to use any influence we obtain over AGIâs deployment to ensure it is used for the benefit of all, and to avoid enabling uses of AI or AGI that harm humanity or unduly concentrateÂ power.Our primary fiduciary duty is to humanity. We anticipate needing to marshal substantial resources to fulfill our mission, but will always diligently act to minimize conflicts of interest among our employees and stakeholders that could compromise broadÂ benefit.Long-term safetyWe are committed to doing the research required to make AGI safe, and to driving the broad adoption of such research across the AIÂ community.We are concerned about late-stage AGI development becoming a competitive race without time for adequate safety precautions. Therefore, if a value-aligned, safety-conscious project comes close to building AGI before we do, we commit to stop competing with and start assisting this project. We will work out specifics in case-by-case agreements, but a typical triggering condition might be âa better-than-even chance of success in the next twoÂ years.âTechnical leadershipTo be effective at addressing AGIâs impact on society, OpenAI must be on the cutting edge of AI capabilitiesâpolicy and safety advocacy alone would beÂ insufficient.We believe that AI will have broad societal impact before AGI, and weâll strive to lead in those areas that are directly aligned with our mission andÂ expertise.Cooperative orientationWe will actively cooperate with other research and policy institutions; we seek to create a global community working together to address AGIâs globalÂ challenges.We are committed to providing public goods that help society navigate the path to AGI. Today this includes publishing most of our AI research, but we expect that safety and security concerns will reduce our traditional publishing in the future, while increasing the importance of sharing safety, policy, and standardsÂ research.ResearchOverviewIndexProductOverviewChatGPTGPT-4DALLÂ·E 2Customer storiesSafety standardsAPI data privacyPricingSafetyOverviewCompanyAboutBlogCareersCharterSecurityOpenAI Â© 2015âââ2023Terms & policiesPrivacy policyBrand guidelinesSocialTwitterYouTubeGitHubSoundCloudLinkedInBack to top
