


New and improved content moderation tooling












CloseSearch Submit Skip to main contentSite NavigationResearchOverviewIndexProductOverviewChatGPTGPT-4DALLÂ·E 2Customer storiesSafety standardsAPI data privacyPricingDevelopersOverviewDocumentationAPI referenceExamplesSafetyCompanyAboutBlogCareersCharterSecuritySearch Navigation quick links Log inSign upMenu Mobile Navigation CloseSite NavigationResearchProductDevelopersSafetyCompany Quick Links Log inSign upSearch Submit New and improved content moderation toolingWe are introducing a new and improved content moderation tool. TheÂ Moderation endpointÂ improves upon our previous content filter, and is available for free today to OpenAI APIÂ developers.Illustration: Ruby ChenAugust 10, 2022AuthorsTodor MarkovChong ZhangSandhini AgarwalTyna EloundouTeddy LeeSteven AdlerAngela JiangLilian WengProduct,Â AnnouncementsTo help developers protect their applications against possible misuse, we are introducing the faster and more accurateÂ Moderation endpoint. This endpoint provides OpenAI API developers with free access toÂ GPT-basedÂ classifiers that detect undesired contentâan instance ofÂ using AI systemsÂ to assist with human supervision of these systems. We have also released both aÂ technical paperÂ describing our methodology and theÂ datasetÂ used forÂ evaluation.When given a text input, the Moderation endpoint assesses whether the content is sexual, hateful, violent, or promotes self-harmâcontent prohibited by ourÂ content policy. The endpoint has been trained to be quick, accurate, and to perform robustly across a range of applications. Importantly, this reduces the chances of products âsayingâ the wrong thing, even when deployed to users at-scale. As a consequence, AI can unlock benefits in sensitive settings, like education, where it could not otherwise be used withÂ confidence.input text Violence  Self-harm  Hate  Sexual Moderation endpointFlaggedFlaggedThe Moderation endpoint helps developers to benefit from our infrastructure investments. Rather than build and maintain their own classifiersâan extensive process, as we document in ourÂ paperâthey can instead access accurate classifiers through a single APIÂ call.As part of OpenAIâsÂ commitmentÂ toÂ making the AI ecosystem safer, we are providing this endpoint to allow free moderation of all OpenAI API-generated content. For instance,Â Inworld, an OpenAI API customer, uses the Moderation endpoint to help their AI-based virtual characters remain appropriate for their audiences. By leveraging OpenAIâs technology, Inworld can focus on their core product: creating memorable characters. We currently do not support monitoring of third-partyÂ traffic.Get started with the Moderation endpoint by checking outÂ the documentation. More details of the training process and model performance are available in ourÂ paper. We have also released anÂ evaluation dataset, featuring Common Crawl data labeled within these categories, which we hope will spur further research in thisÂ area.View documentationAuthorsTodor MarkovView all articlesChong ZhangView all articlesSandhini AgarwalView all articlesTyna EloundouView all articlesTeddy LeeView all articlesSteven AdlerView all articlesAngela JiangView all articlesLilian WengView all articlesResearchOverviewIndexProductOverviewChatGPTGPT-4DALLÂ·E 2Customer storiesSafety standardsAPI data privacyPricingSafetyOverviewCompanyAboutBlogCareersCharterSecurityOpenAI Â© 2015âââ2023Terms & policiesPrivacy policyBrand guidelinesSocialTwitterYouTubeGitHubSoundCloudLinkedInBack to top
