


OpenAI Microscope












CloseSearch Submit Skip to main contentSite NavigationResearchOverviewIndexProductOverviewChatGPTGPT-4DALLÂ·E 2Customer storiesSafety standardsAPI data privacyPricingDevelopersOverviewDocumentationAPI referenceExamplesSafetyCompanyAboutBlogCareersCharterSecuritySearch Navigation quick links Log inSign upMenu Mobile Navigation CloseSite NavigationResearchProductDevelopersSafetyCompany Quick Links Log inSign upSearch Submit OpenAI MicroscopeIllustration: Ben BarryWeâre introducingÂ OpenAI Microscope, a collection of visualizations of every significant layer and neuron of eight vision âmodel organismsâ which are often studied in interpretability. Microscope makes it easier to analyze the features that form inside these neural networks, and we hope it will help the research community as we move towards understanding these complicatedÂ systems.April 14, 2020More resourcesBrowse MicroscopeInterpretability,Â Computer vision,Â ReleaseThe abilities of modern neural networks are the result of the interactions of thousands of neurons (sometimes tens of thousands or more!). In order to understand their behavior, weâd like to be able to quickly and easily investigate these neurons interactions in detail, and share those observations. This is especially true in collaborative environments. For instance, one researcher mightÂ speculate:InceptionV1Â 4c:447Â is a car detector which is built from a wheel detector (4b:373) and a window detector (4b:237).When someone makes a claim like this, itâs useful if others can quickly explore those neurons, evaluating the claim and discovering new things. This is the goal of the OpenAIÂ Microscope.Microscope systematically visualizes every neuron in several commonly studied vision models, and makes all of those neurons linkable. We hope this will support the interpretability community in severalÂ ways:Although these models and visualizations are already open source (we help maintain theÂ lucid library, which is used to generate all the visualizations in Microscope) visualizing neurons is tedious. Microscope changes the feedback loop of exploring neurons from minutes to seconds. This quick feedback loop has been essential for us in discovering unexpected features like high-low frequency detectors in the ongoingÂ circuitsÂ project.Making models and neurons linkable allows immediate scrutiny and further exploration of research making claims about those neurons. It also removes potential confusion about which model and neuron is being discussed (which of the five versions of InceptionV1 are we talking about again?). This is really helpful for collaboration, especially when researchers are at differentÂ institutions.One of the wonderful things about interpretability as an area of ML is how accessible it is. Compared to many other areas, it requires comparatively little access to compute. But systematically visualizing neural networks can still take hundreds of GPU hours. We hope that, by sharing our visualizations, we can help keep interpretability highlyÂ accessible.Just as biologists often focus on the study of a few âmodel organisms,â Microscope focuses on exploring a small number of models in detail. Our initial release includes nine frequently studied vision models, along with several visualization techniques weâve found particularly useful in studying them. We plan to expand to other models and techniques in the comingÂ months.Weâre excited to see how the community will use Microscope, and we encourage you to reuse these assets. In particular, we think it has a lot of potential in supporting theÂ Circuits collaborationâa project to reverse engineer neural networks by analyzing individual neurons and their connectionsâor similarÂ work.AuthorsMain contributorsLudwig SchubertMichael PetrovShan CarterContributorsNick CammarataGabriel GohChris OlahResearchOverviewIndexProductOverviewChatGPTGPT-4DALLÂ·E 2Customer storiesSafety standardsAPI data privacyPricingSafetyOverviewCompanyAboutBlogCareersCharterSecurityOpenAI Â© 2015âââ2023Terms & policiesPrivacy policyBrand guidelinesSocialTwitterYouTubeGitHubSoundCloudLinkedInBack to top
