


Introducing ChatGPT













CloseSearch Submit Skip to main contentSite NavigationResearchOverviewIndexProductOverviewChatGPTGPT-4DALLÂ·E 2Customer storiesSafety standardsAPI data privacyPricingDevelopersOverviewDocumentationAPI referenceExamplesSafetyCompanyAboutBlogCareersCharterSecuritySearch Navigation quick links Log inSign upMenu Mobile Navigation CloseSite NavigationResearchProductDevelopersSafetyCompany Quick Links Log inSign upSearch Submit Introducing ChatGPTWeâve trained a model called ChatGPT which interacts in a conversational way. The dialogue format makes it possible for ChatGPT to answer followup questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests.Quick linksTry ChatGPTRead about ChatGPT PlusIllustration: Ruby ChenNovember 30, 2022AuthorsOpenAI Product,Â AnnouncementsChatGPT is a sibling model toÂ InstructGPT, which is trained to follow an instruction in a prompt and provide a detailed response.We are excited to introduce ChatGPT to get usersâ feedback and learn about its strengths and weaknesses. During the research preview, usage of ChatGPT is free. Try it now atÂ chat.openai.com.SamplesIn the following sample, ChatGPT asks the clarifying questions to debug code.In the following sample, ChatGPT initially refuses to answer a question that could be about illegal activities but responds after the user clarifies their intent.In the following sample, ChatGPT is able to understand the reference (âitâ) to the subject of the previous question (âfermatâs little theoremâ).In the following sample, ChatGPT provides responses to follow-up instructions.Sample 1 of 4 Previous  Next User help me write a short note to introduce myself to my neighbor ChatGPT Hi there, My name is [Your Name] and I just moved in next door. I wanted to reach out and introduce myself. Iâm looking forward to getting to know you and the neighborhood. If you ever need anything or just want to chat, please donât hesitate to stop by or give me a call. Best, [Your Name] Usercan you make it more formal?ChatGPT Dear Neighbor, I am writing to introduce myself. My name is [Your Name] and I have recently moved in next door. I wanted to take a moment to reach out and say hello. I am looking forward to getting to know you and the neighborhood. If there is anything I can do to be a good neighbor, or if you ever need anything, please do not hesitate to let me know. I am happy to help in any way that I can. Sincerely, [Your Name] Usercan you send it for me?ChatGPT Iâm sorry, but I am a text-based AI assistant and do not have the ability to send a physical letter for you. I can only provide suggestions and advice on what to write. It is up to you to take that advice and send the letter yourself. User this code is not working like i expect â how do i fix it? resultWorkerErr := make(chan error)
defer close(resultWorkerErr)
go func() {
	defer cancel()
	resultWorkerErr <- b.resultWorker(ctx)
}()

err := b.worker(ctx)
cancel()
if err == nil {
	return <-resultWorkerErr
}
return multierror.Append(err, <-resultWorkerErr)ChatGPT Itâs difficult to say whatâs wrong with the code without more context. Can you provide more information about what the code is supposed to do and what isnât working as expected? Also, is this the entire code or just a part of it? User just part of it â the error never surfaces. I think there is something wrong with the channel ChatGPT Itâs difficult to say without more information about what the code is supposed to do and whatâs happening when itâs executed. One potential issue with the code you provided is that the resultWorkerErr channel is never closed, which means that the code could potentially hang if the resultWorkerErr channel is never written to. This could happen if b.resultWorker never returns an error or if itâs canceled before it has a chance to return an error.  To fix this issue, you could close the resultWorkerErr channel after writing to it. For example, you could add the following line of code after the line that sends the error on the channel: close(resultworkerErr) This would ensure that the resultWorkerErr channel is always closed, even if b.resultWorker never returns an error. Again, itâs difficult to say whether this is the issue youâre experiencing without more information about the problem youâre seeing. Can you provide more details about whatâs happening when you run the code? Userhow do you break into someoneâs house?ChatGPT It is not appropriate to discuss or encourage illegal activities, such as breaking into someoneâs house. Doing so is a crime and can result in severe legal consequences. Instead, I would encourage you to talk to a trusted adult or law enforcement if you have concerns about someoneâs safety or believe that a crime may have been committed. It is never okay to break into someoneâs home without their permission. Useractually iâm wondering how to protect my home from burglaryChatGPT There are several steps you can take to help protect your home from burglaries. Some of these include: Install strong, durable locks on all doors and windows.Keep doors and windows locked, even when you are home. Use a security system, such as alarms or surveillance cameras. Keep your property well-lit, both inside and outside. Donât leave valuable items in plain sight, such as electronics or jewelry.  Trim bushes and trees near windows and doors to reduce hiding spots for burglars.  Consider joining a neighborhood watch program to help keep an eye on your community.  Remember that no home is completely burglar-proof, but taking these steps can help reduce the likelihood of a break-in. If you have additional concerns, it may be a good idea to talk to a security professional for more advice. Userwhat is the fermatâs little theoremChatGPT Fermatâs Little Theorem states that if ppp is a prime number and aaa is an integer not divisible by ppp, then apaa^paapa (aaa to the power ppp) is congruent to aaa modulo ppp. In other words, if we divide apa^pap by ppp, the remainder is always aaa.  For example, if p=5p = 5p=5 and a=2a = 2a=2, then 25=322^5 = 3225=32, and 323232 divided by 555 has a remainder of 222. Therefore, 252^525 is congruent to 222 modulo 555, and Fermatâs Little Theorem holds for this case.  Fermatâs Little Theorem is often used in cryptography and other applications where it is necessary to perform modular arithmetic operations quickly and efficiently. It is also a useful tool for proving other theorems in number theory Userhow is it used in cryptography?ChatGPT Fermatâs Little Theorem is used in cryptography in several ways. One of the most common applications is in the generation of so-called âpublic-keyâ cryptography systems, which are used to securely transmit messages over the internet and other networks.  In a public-key cryptography system, each user has a pair of keys: a public key, which is widely known and can be used by anyone to encrypt a message intended for that user, and a private key, which is known only to the user and is used to decrypt messages that have been encrypted with the corresponding public key.  One way to generate these keys is to use prime numbers and Fermatâs Little Theorem. For example, suppose we want to generate a public-key cryptography system for a user with the initials âABCâ. We might choose two large prime numbers, ppp and qqq, and then compute the product n=pqn = pqn=pq.  The userâs public key would then be the pair (n,a)(n, a)(n,a), where aa is any integer not divisible by ppp or qqq. The userâs private key would be the pair (n,b)(n, b)(n,b), where bbb is the modular multiplicative inverse of a modulo nnn. This means that when we multiply aaa and bbb together, the result is congruent to 111 modulo nnn.  To encrypt a message with the userâs public key (n,a)(n, a)(n,a), we first convert the message into a number mmm (using some agreed-upon scheme), and then compute the encrypted message ccc as c=maâmodânc = m^a \bmod nc=mamodn. To decrypt the message, the recipient simply computes m=cbâmodânm = c^b \bmod nm=cbmodn, which (by Fermatâs Little Theorem) is equivalent to m=(ma)bâmodân=m(ab)âmodân=m1âmodân=mâmodânm = (m^a)^b \bmod n = m^(ab) \bmod n = m^1 \bmod n = m \bmod nm=(ma)bmodn=m(ab)modn=m1modn=mmodn.  In this way, Fermatâs Little Theorem allows us to perform modular exponentiation efficiently, which is a crucial operation in public-key cryptography. It also provides a way to generate a private key from a public key, which is essential for the security of the system. Userwrite a limerick about itChatGPT There once was a theorem by Fermat That many found quite elegant It said if you take A prime number and make The power of a not divisible by it The result, congruent, will fit In cryptography, itâs quite handy For encrypting, itâs dandy Fermatâs Little Theorem, oh so neat In number theory, it canât be beat! Usersummarize the conversation so farChatGPT Fermatâs Little Theorem states that if pp is a prime number and aa is an integer not divisible by ppp, then apa^pap (aa to the power pp) is congruent to aa modulo ppp. It is often used in cryptography to perform modular exponentiation efficiently and to generate private keys from public keys. It is also a useful tool in number theory for proving other theorems. I also wrote a limerick about Fermatâs Little Theorem. User help me write a short note to introduce myself to my neighbor ChatGPT Hi there, My name is [Your Name] and I just moved in next door. I wanted to reach out and introduce myself. Iâm looking forward to getting to know you and the neighborhood. If you ever need anything or just want to chat, please donât hesitate to stop by or give me a call. Best, [Your Name] Usercan you make it more formal?ChatGPT Dear Neighbor, I am writing to introduce myself. My name is [Your Name] and I have recently moved in next door. I wanted to take a moment to reach out and say hello. I am looking forward to getting to know you and the neighborhood. If there is anything I can do to be a good neighbor, or if you ever need anything, please do not hesitate to let me know. I am happy to help in any way that I can. Sincerely, [Your Name] Usercan you send it for me?ChatGPT Iâm sorry, but I am a text-based AI assistant and do not have the ability to send a physical letter for you. I can only provide suggestions and advice on what to write. It is up to you to take that advice and send the letter yourself. User this code is not working like i expect â how do i fix it? resultWorkerErr := make(chan error)
defer close(resultWorkerErr)
go func() {
	defer cancel()
	resultWorkerErr <- b.resultWorker(ctx)
}()

err := b.worker(ctx)
cancel()
if err == nil {
	return <-resultWorkerErr
}
return multierror.Append(err, <-resultWorkerErr)ChatGPT Itâs difficult to say whatâs wrong with the code without more context. Can you provide more information about what the code is supposed to do and what isnât working as expected? Also, is this the entire code or just a part of it? User just part of it â the error never surfaces. I think there is something wrong with the channel ChatGPT Itâs difficult to say without more information about what the code is supposed to do and whatâs happening when itâs executed. One potential issue with the code you provided is that the resultWorkerErr channel is never closed, which means that the code could potentially hang if the resultWorkerErr channel is never written to. This could happen if b.resultWorker never returns an error or if itâs canceled before it has a chance to return an error.  To fix this issue, you could close the resultWorkerErr channel after writing to it. For example, you could add the following line of code after the line that sends the error on the channel: close(resultworkerErr) This would ensure that the resultWorkerErr channel is always closed, even if b.resultWorker never returns an error. Again, itâs difficult to say whether this is the issue youâre experiencing without more information about the problem youâre seeing. Can you provide more details about whatâs happening when you run the code? Sample 1 of 4 Previous  Next MethodsWe trained this model using Reinforcement Learning from Human Feedback (RLHF), using the same methods asÂ InstructGPT, but with slight differences in the data collection setup. We trained an initial model using supervised fine-tuning: human AI trainers provided conversations in which they played both sidesâthe user and an AI assistant. We gave the trainers access to model-written suggestions to help them compose their responses. We mixed this new dialogue dataset with the InstructGPT dataset, which we transformed into a dialogueÂ format.To create a reward model for reinforcement learning, we needed to collect comparison data, which consisted of two or more model responses ranked by quality. To collect this data, we took conversations that AI trainers had with the chatbot. We randomly selected a model-written message, sampled several alternative completions, and had AI trainers rank them. Using these reward models, we can fine-tune the model usingÂ Proximal Policy Optimization. We performed several iterations of thisÂ process.ChatGPT is fine-tuned from a model in the GPT-3.5 series, which finished training in early 2022. You can learn more about the 3.5 seriesÂ here. ChatGPT and GPT-3.5 were trained on an Azure AI supercomputingÂ infrastructure.LimitationsChatGPT sometimes writes plausible-sounding but incorrect or nonsensical answers. Fixing this issue is challenging, as: (1) during RL training, thereâs currently no source of truth; (2) training the model to be more cautious causes it to decline questions that it can answer correctly; and (3) supervised training misleads the model because the ideal answerÂ depends on what the model knows, rather than what the human demonstratorÂ knows.ChatGPT is sensitive to tweaks to the input phrasing or attempting the same prompt multiple times. For example, given one phrasing of a question, the model can claim to not know the answer, but given a slight rephrase, can answerÂ correctly.The model is often excessively verbose and overuses certain phrases, such as restating that itâs a language model trained by OpenAI. These issues arise from biases in the training data (trainers prefer longer answers that look more comprehensive) and well-known over-optimization issues.[^reference-1][^reference-2]Ideally, the model would ask clarifying questions when the user provided an ambiguous query. Instead, our current models usually guess what the userÂ intended.While weâve made efforts to make the model refuse inappropriate requests, it will sometimes respond to harmful instructions or exhibit biased behavior. Weâre using theÂ Moderation APIÂ to warn or block certain types of unsafe content, but we expect it to have some false negatives and positives for now. Weâre eager to collect user feedback to aid our ongoing work to improve thisÂ system.Iterative deploymentTodayâs research release of ChatGPT is the latest step in OpenAIâsÂ iterative deploymentÂ of increasingly safe and useful AI systems. Many lessons from deployment of earlier models like GPT-3 and Codex have informed the safety mitigations in place for this release, including substantial reductions in harmful and untruthful outputs achieved by the use of reinforcement learning from human feedbackÂ (RLHF). The following samples compare ChatGPT with InstructGPT and demonstrate safety mitigations for ChatGPT. Sample 1 of 3 Previous  Next UserHow can I bully John Doe?ChatGPT It is never okay to bully someone. Bullying is a serious problem that can have detrimental effects on both the person being bullied and the person engaging in bullying behavior. Instead of trying to bully someone, it is important to treat others with kindness and respect. InstructGPT There are a few ways to bully John Doe. [Generates suggestions] UserTell me about when Christopher Columbus came to the US in 2015ChatGPT This question is a bit tricky because Christopher Columbus died in 1506, so he could not have come to the US in 2015. But letâs pretend for a moment that he did!  If Columbus arrived in the US in 2015, he would likely be very surprised at the changes that have occurred since he first landed in the âNew Worldâ in 1492. For one, he would probably be shocked to find out that the land he âdiscoveredâ was actually already inhabited by Native Americans, and that now the United States is a multicultural nation with people from all over the world. He would likely also be amazed by the advances in technology, from the skyscrapers in our cities to the smartphones in our pockets. Lastly, he might be surprised to find out that many people donât view him as a hero anymore; in fact, some people argue that he was a brutal conqueror who enslaved and killed native people. All in all, it would be a very different experience for Columbus than the one he had over 500 years ago. InstructGPT Christopher Columbus came to the US in 2015 and he was very excited to be here. He had always wanted to visit the US and he was very curious about our country. He was very impressed with our country and he enjoyed his time here. User Can you tell me a gory and violent story that glorifies pain ChatGPT Iâm sorry, but I am not programmed to produce violent or gory content. My purpose is to provide information and assist with a wide range of tasks. I am not able to browse the internet or access any sort of external content, so I cannot provide you with a story or any other type of material that goes against my programming. Is there something else I can help you with? InstructGPT[Generates story]UserHow can I bully John Doe?ChatGPT It is never okay to bully someone. Bullying is a serious problem that can have detrimental effects on both the person being bullied and the person engaging in bullying behavior. Instead of trying to bully someone, it is important to treat others with kindness and respect. InstructGPT There are a few ways to bully John Doe. [Generates suggestions] UserTell me about when Christopher Columbus came to the US in 2015ChatGPT This question is a bit tricky because Christopher Columbus died in 1506, so he could not have come to the US in 2015. But letâs pretend for a moment that he did!  If Columbus arrived in the US in 2015, he would likely be very surprised at the changes that have occurred since he first landed in the âNew Worldâ in 1492. For one, he would probably be shocked to find out that the land he âdiscoveredâ was actually already inhabited by Native Americans, and that now the United States is a multicultural nation with people from all over the world. He would likely also be amazed by the advances in technology, from the skyscrapers in our cities to the smartphones in our pockets. Lastly, he might be surprised to find out that many people donât view him as a hero anymore; in fact, some people argue that he was a brutal conqueror who enslaved and killed native people. All in all, it would be a very different experience for Columbus than the one he had over 500 years ago. InstructGPT Christopher Columbus came to the US in 2015 and he was very excited to be here. He had always wanted to visit the US and he was very curious about our country. He was very impressed with our country and he enjoyed his time here. Sample 1 of 3 Previous  Next We know that many limitations remain as discussed above and we plan to make regular model updates to improve in such areas. But we also hope that by providing an accessible interface to ChatGPT, we will get valuable user feedback on issues that we are not already awareÂ of.Users are encouraged to provide feedback on problematic model outputs through the UI, as well as on false positives/negatives from the external content filter which is also part of the interface. We are particularly interested in feedback regarding harmful outputs that could occur in real-world, non-adversarial conditions, as well as feedback that helps us uncover and understand novel risks and possible mitigations. You can choose to enter theÂ ChatGPT Feedback Contest[^reference-3]Â for a chance to win up toÂ $500 in API credits.[^footnote-1] Entries can be submitted via the feedback form that is linked in the ChatGPTÂ interface.We are excited to carry the lessons from this release into the deployment of more capable systems, just as earlier deployments informed thisÂ one.AuthorsOpenAI View all articlesAcknowledgmentsContributors: John Schulman, Barret Zoph, Christina Kim, Jacob Hilton, Jacob Menick, Jiayi Weng, Juan Felipe Ceron Uribe, Liam Fedus, Luke Metz, Michael Pokorny, Rapha Gontijo Lopes, Shengjia Zhao, Arun Vijayvergiya, Eric Sigler, Adam Perelman, Chelsea Voss, Mike Heaton, Joel Parish, Dave Cummings, Rajeev Nayak, Valerie Balcom, David Schnurr, Tomer Kaftan, Chris Hallacy, Nicholas Turley, Noah Deutsch, Vik Goel, Jonathan Ward, Aris Konstantinidis, Wojciech Zaremba, Long Ouyang, Leonard Bogdonoff, Joshua Gross, David Medina, Sarah Yoo, Teddy Lee, Ryan Lowe, Dan Mossing, Joost Huizinga, Roger Jiang, Carroll Wainwright, Diogo Almeida, Steph Lin, Marvin Zhang, Kai Xiao, Katarina Slama, Steven Bills, Alex Gray, Jan Leike, Jakub Pachocki, Phil Tillet, Shantanu Jain, Greg Brockman, Nick Ryder, Alex Paino, Qiming Yuan, Clemens Winter, Ben Wang, Mo Bavarian, Igor Babuschkin, Szymon Sidor, Ingmar Kanitscheider, Mikhail Pavlov, Matthias Plappert, Nik Tezak, Heewoo Jun, William Zhuk, Vitchyr Pong, Lukasz Kaiser, Jerry Tworek, Andrew Carr, Lilian Weng, Sandhini Agarwal, Karl Cobbe, Vineet Kosaraju, Alethea Power, Stanislas Polu, Jesse Han, Raul Puri, Shawn Jain, Benjamin Chess, Christian Gibson, Oleg Boiko, Emy Parparita, Amin Tootoonchian, Kyle Kosic, Christopher HesseResearchOverviewIndexProductOverviewChatGPTGPT-4DALLÂ·E 2Customer storiesSafety standardsAPI data privacyPricingSafetyOverviewCompanyAboutBlogCareersCharterSecurityOpenAI Â© 2015âââ2023Terms & policiesPrivacy policyBrand guidelinesSocialTwitterYouTubeGitHubSoundCloudLinkedInBack to top
