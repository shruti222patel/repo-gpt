


DALL·E: Creating images from text












CloseSearch Submit Skip to main contentSite NavigationResearchOverviewIndexProductOverviewChatGPTGPT-4DALLÂ·E 2Customer storiesSafety standardsAPI data privacyPricingDevelopersOverviewDocumentationAPI referenceExamplesSafetyCompanyAboutBlogCareersCharterSecuritySearch Navigation quick links Log inSign upMenu Mobile Navigation CloseSite NavigationResearchProductDevelopersSafetyCompany Quick Links Log inSign upSearch Submit Illustration: Justin Jay WangDALLÂ·E: Creating images from textWeâve trained a neural network called DALLÂ·E that creates images from text captions for a wide range of concepts expressible in naturalÂ language.January 5, 2021Image generation,Â Transformers,Â Generative models,Â DALLÂ·E,Â GPT-2,Â CLIP,Â Milestone,Â Publication,Â ReleaseDALLÂ·E is a 12-billion parameter version ofÂ GPT-3Â trained to generate images from text descriptions, using a dataset of textâimage pairs. Weâve found that it has a diverse set of capabilities, including creating anthropomorphized versions of animals and objects, combining unrelated concepts in plausible ways, rendering text, and applying transformations to existingÂ images.See also:Â DALLÂ·E 2, which generates more realistic and accurate images with 4x greaterÂ resolution.Text Promptan illustration of a baby daikon radish in a tutu walking a dogAI Generated imagesEdit prompt or view more imagesText Promptan armchair in the shape of an avocado. . . .AI Generated imagesEdit prompt or view more imagesText Prompta store front that has the word âopenaiâ written on it. . . .AI Generated imagesEdit prompt or view more imagesText Promptthe exact same cat on the top as a sketch on the bottomAI Generated imagesEdit prompt or view more imagesGPT-3 showed that language can be used to instruct a large neural network to perform a variety of text generation tasks.Â Image GPTÂ showed that the same type of neural network can also be used to generate images with high fidelity. We extend these findings to show that manipulating visual concepts through language is now withinÂ reach.OverviewLike GPT-3, DALLÂ·E is a transformer language model. It receives both the text and the image as a single stream of data containing up to 1280 tokens, and is trained using maximum likelihood to generate all of the tokens, one after another. [^footnote-1]This training procedure allows DALLÂ·E to not only generate an image from scratch, but also to regenerate any rectangular region of an existing image that extends to the bottom-right corner, in a way that is consistent with the textÂ prompt.We recognize that work involving generative models has the potential for significant, broad societal impacts. In the future, we plan to analyze how models like DALLÂ·E relate to societal issues like economic impact on certain work processes and professions, the potential for bias in the model outputs, and the longer term ethical challenges implied by thisÂ technology.CapabilitiesWe find that DALLÂ·E is able to create plausible images for a great variety of sentences that explore the compositional structure of language. We illustrate this using a series of interactive visuals in the next section. The samples shown for each caption in the visuals are obtained by taking the top 32 of 512 after reranking withÂ CLIP, but we do not use any manual cherry-picking, aside from the thumbnails and standalone images that appear outside.[^footnote-2]Controlling attributesWe test DALLÂ·Eâs ability to modify several of an objectâs attributes, as well as the number of times that itÂ appears. Click to edit text prompt or view more AI-generated images a pentagonal green click. a green clock in the shape of a pentagon.Text PromptAI generated imagesWe find that DALLÂ·E can render familiar objects in polygonal shapes that are sometimes unlikely to occur in the real world. For some objects, such as âpicture frameâ and âplate,â DALLÂ·E can reliably draw the object in any of the polygonal shapes except heptagon. For other objects, such as âmanhole coverâ and âstop sign,â DALLÂ·Eâs success rate for more unusual shapes, such as âpentagon,â is considerably lower.For several of the visuals in this post, we find that repeating the caption, sometimes with alternative phrasings, improves the consistency of the results.a cube made of porcupine. a cube with the texture of a porcupine.Text PromptAI generated imagesWe find that DALLÂ·E can map the textures of various plants, animals, and other objects onto three dimensional solids. As in the preceding visual, we find that repeating the caption with alternative phrasing improves the consistency of the results.a collection of glasses is sitting on a tableText PromptAI generated images We find that DALLÂ·E is able to draw multiple copies of an object when prompted to do so, but is unable to reliably count past three. When prompted to draw nouns for which there are multiple meanings, such as âglasses,â âchips,â and âcupsâ it sometimes draws both interpretations, depending on the plural form that is used.Drawing multiple objectsSimultaneously controlling multiple objects, their attributes, and their spatial relationships presents a new challenge. For example, consider the phrase âa hedgehog wearing a red hat, yellow gloves, blue shirt, and green pants.â To correctly interpret this sentence, DALLÂ·E must not only correctly compose each piece of apparel with the animal, but also form the associations (hat, red), (gloves, yellow), (shirt, blue), and (pants, green) without mixing them up [^footnote-3]Â We test DALLÂ·Eâs ability to do this for relative positioning, stacking objects, and controlling multipleÂ attributes.a small red block sitting on a large green blockText PromptAI generated imagesWe find that DALLÂ·E correctly responds to some types of relative positions, but not others. The choices âsitting onâ and âstanding in front ofâ sometimes appear to work, âsitting below,â âstanding behind,â âstanding left of,â and âstanding right ofâ do not. DALLÂ·E also has a lower success rate when asked to draw a large object sitting on top of a smaller one, when compared to the other way around.a stack of 3 cubes. a red cube is on the top, sitting on a green cube. the green cube is in the middle, sitting on a blue cube. the blue cube is on the bottom.Text PromptAI generated imagesWe find that DALLÂ·E typically generates an image with one or two of the objects having the correct colors. However, only a few samples for each setting tend to have exactly three objects colored precisely as specified.an emoji of a baby penguin wearing a blue hat, red gloves, green shirt, and yellow pantsText PromptAI generated imagesWe find that DALLÂ·E typically generates an image with two or three articles of clothing having the correct colors. However, only a few of the samples for each setting tend to have all four articles of clothing with the specified colors.While DALLÂ·E does offer some level of controllability over the attributes and positions of a small number of objects, the success rate can depend on how the caption is phrased. As more objects are introduced, DALLÂ·E is prone to confusing the associations between the objects and their colors, and the success rate decreases sharply. We also note that DALLÂ·E is brittle with respect to rephrasing of the caption in these scenarios: alternative, semantically equivalent captions often yield no correctÂ interpretations.Visualizing perspective and three-dimensionalityWe find that DALLÂ·E also allows for control over the viewpoint of a scene and the 3D style in which a scene isÂ rendered.an extreme close-up view of a capybara sitting in a fieldText PromptAI generated imagesWe find that DALLÂ·E can draw each of the animals in a variety of different views. Some of these views, such as âaerial viewâ and ârear view,â require knowledge of the animalâs appearance from unusual angles. Others, such as âextreme close-up view,â require knowledge of the fine-grained details of the animalâs skin or fur.a capybara made of voxels sitting in a fieldText PromptAI generated imagesWe find that DALLÂ·E is often able to modify the surface of each of the animals according to the chosen 3D style, such as âclaymationâ and âmade of voxels,â and render the scene with plausible shading depending on the location of the sun. The âx-rayâ style does not always work reliably, but it shows that DALLÂ·E can sometimes orient the bones within the animal in plausible (though not anatomically correct) configurations.To push this further, we test DALLÂ·Eâs ability to repeatedly draw the head of a well-known figure at each angle from a sequence of equally spaced angles, and find that we can recover a smooth animation of the rotatingÂ head.a photograph of a bust of homerText PromptImage PromptAI generated imagesWe prompt DALLÂ·E with both a caption describing a well-known figure and the top region of an image showing a hat drawn at a particular angle. Then, we ask DALLÂ·E to complete the remaining part of the image given this contextual information. We do this repeatedly, each time rotating the hat a few more degrees, and find that we are able to recover smooth animations of several well-known figures, with each frame respecting the precise specification of angle and ambient lighting. DALLÂ·E appears to be able to apply some types of optical distortions to scenes, as we see with the options âfisheye lens viewâ and âa spherical panorama.â This motivated us to explore its ability to generateÂ reflections.a plain white cube looking at its own reflection in a mirror. a plain white cube gazing at itself in a mirror.Text PromptImage PromptAI generated imagesWe prompt DALLÂ·E with both a caption describing a well-known figure and the top region of an image showing a hat drawn at a particular angle. Then, we ask DALLÂ·E to complete the remaining part of the image given this contextual information. We do this repeatedly, each time rotating the hat a few more degrees, and find that we are able to recover smooth animations of several well-known figures, with each frame respecting the precise specification of angle and ambient lighting. Visualizing internal and external structureThe samples from the âextreme close-up viewâ and âx-rayâ style led us to further explore DALLÂ·Eâs ability to render internal structure with cross-sectional views, and external structure with macroÂ photographs.a cross-section view of a walnutText PromptAI generated imagesWe find that DALLÂ·E is able to draw the interiors of several different kinds of objects.a macro photograph of brain coralText PromptAI generated imagesWe find that DALLÂ·E is able to draw the fine-grained external details of several different kinds of objects. These details are only apparent when the object is viewed up close.Inferring contextual detailsThe task of translating text to images is underspecified: a single caption generally corresponds to an infinitude of plausible images, so the image is not uniquely determined. For instance, consider the caption âa painting of a capybara sitting on a field at sunrise.â Depending on the orientation of the capybara, it may be necessary to draw a shadow, though this detail is never mentioned explicitly. We explore DALLÂ·Eâs ability to resolve underspecification in three cases: changing style, setting, and time; drawing the same object in a variety of different situations; and generating an image of an object with specific text written onÂ it.a painting of a capybara sitting in a field at sunriseText PromptAI generated imagesWe find that DALLÂ·E is able to render the same scene in a variety of different styles, and can adapt the lighting, shadows, and environment based on the time of day or season.a stained glass window with an image of a blue strawberryText PromptAI generated imagesWe find that DALLÂ·E is able to flexibly adapt the representation of the object based on the medium on which it is being drawn. For âa mural,â âa soda can,â and âa teacup,â DALLÂ·E must change how it draws the object based on the angle and curvature of the drawing surface. For âa stained glass windowâ and âa neon sign,â it must alter the appearance of the object from how it usually appears.a store front that has the word âopenaiâ written on it. a store front that has the word âopenaiâ written on it. a store front that has the word âopenaiâ written on it. âopenaiâ store front.Text PromptAI generated imagesWe find that DALLÂ·E is able to draw the fine-grained external details of several different kinds of objects. These details are only apparent when the object is viewed up close.With varying degrees of reliability, DALLÂ·E provides access to a subset of the capabilities of a 3D rendering engine via natural language. It can independently control the attributes of a small number of objects, and to a limited extent, how many there are, and how they are arranged with respect to one another. It can also control the location and angle from which a scene is rendered, and can generate known objects in compliance with precise specifications of angle and lightingÂ conditions.Unlike a 3D rendering engine, whose inputs must be specified unambiguously and in complete detail, DALLÂ·E is often able to âfill in the blanksâ when the caption implies that the image must contain a certain detail that is not explicitlyÂ stated.Applications of preceding capabilitiesNext, we explore the use of the preceding capabilities for fashion and interiorÂ design.a male mannequin dressed in an orange and black flannel shirtText PromptImage PromptAI generated imagesWe explore DALLÂ·Eâs ability to render male mannequins in a variety of different outfits. When prompted with two colors, e.g., âan orange and white bomber jacketâ and âan orange and black turtleneck sweater,â DALLÂ·E often exhibits a range of possibilities for how both colors can be used for the same article of clothing.DALLÂ·E also seems to occasionally confuse less common colors with other neighboring shades. For example, when prompted to draw clothes in ânavy,â DALLÂ·E sometimes uses lighter shades of blue, or shades very close to black. Similarly, DALLÂ·E sometimes confuses âoliveâ with shades of brown or brighter shades of green.a female mannequin dressed in a black leather jacket and gold pleated skirtText PromptImage PromptAI generated imagesWe explore DALLÂ·Eâs ability to render female mannequins in a variety of different outfits. We find that DALLÂ·E is able to portray unique textures such as the sheen of a âblack leather jacketâ and âgoldâ skirts and leggings. As before, we see that DALLÂ·E occasionally confuses less common colors, such as ânavyâ and âolive,â with other neighboring shades.a living room with two white armchairs and a painting of the colosseum. the painting is mounted above a modern fireplace.Text PromptImage PromptAI generated imagesWe explore DALLÂ·Eâs ability to generate images of rooms with several details specified. We find that it can generate paintings of a wide range of different subjects, including real-world locations such as âthe colosseumâ and fictional characters like âyoda.â For each subject, DALLÂ·E exhibits a variety of interpretations. While the painting is almost always present in the scene, DALLÂ·E sometimes fails to draw the fireplace or the correct number of armchairs.a loft bedroom with a white bed next to a nightstand. there is a fish tank beside the bed.Text PromptImage PromptAI generated imagesWe explore DALLÂ·Eâs ability to generate bedrooms with several details specified. Despite the fact that we do not tell DALLÂ·E what should go on top of the nightstand or shelf beside the bed, we find that it sometimes decides to place the other specified object on top. As before, we see that it often fails to draw one or more of the specified objects.Combining unrelated conceptsThe compositional nature of language allows us to put together concepts to describe both real and imaginary things. We find that DALLÂ·E also has the ability to combine disparate ideas to synthesize objects, some of which are unlikely to exist in the real world. We explore this ability in two instances: transferring qualities from various concepts to animals, and designing products by taking inspiration from unrelatedÂ concepts.a snail made of harp. a snail with the texture of a harp.Text PromptAI generated imagesWe find that DALLÂ·E can generate animals synthesized from a variety of concepts, including musical instruments, foods, and household items. While not always successful, we find that DALLÂ·E sometimes takes the forms of the two objects into consideration when determining how to combine them. For example, when prompted to draw âa snail made of harp,â it sometimes relates the pillar of the harp to the spiral of the snailâs shell.In a previous section, we saw that as more objects are introduced into the scene, DALLÂ·E is liable to confuse the associations between the objects and their specified attributes. Here, we see a different sort of failure mode: sometimes, rather than binding some attribute of the specified concept (say, âa faucetâ) to the animal (say, âa snailâ), DALLÂ·E just draws the two as separate items.an armchair in the shape of an avocado. an armchair imitating an avocado.Text PromptAI generated imagesIn the preceding visual, we explored DALLÂ·Eâs ability to generate fantastical objects by combining two unrelated ideas. Here, we explore its ability to take inspiration from an unrelated idea while respecting the form of the thing being designed, ideally producing an object that appears to be practically functional. We found that prompting DALLÂ·E with the phrases âin the shape of,â âin the form of,â and âin the style ofâ gives it the ability to do this.When generating some of these objects, such as âan armchair in the shape of an avocadoâ, DALLÂ·E appears to relate the shape of a half avocado to the back of the chair, and the pit of the avocado to the cushion. We find that DALLÂ·E is susceptible to the same kinds of mistakes mentioned in the previous visual.Animal illustrationsIn the previous section, we explored DALLÂ·Eâs ability to combine unrelated concepts when generating images of real-world objects. Here, we explore this ability in the context of art, for three kinds of illustrations: anthropomorphized versions of animals and objects, animal chimeras, andÂ emojis.an illustration of a baby daikon radish in a tutu walking a dogText PromptAI generated imagesWe find that DALLÂ·E is sometimes able to transfer some human activities and articles of clothing to animals and inanimate objects, such as food items. We include âpikachuâ and âwielding a blue lightsaberâ to explore DALLÂ·Eâs ability to incorporate popular media.We find it interesting how DALLÂ·E adapts human body parts onto animals. For example, when asked to draw a daikon radish blowing its nose, sipping a latte, or riding a unicycle, DALLÂ·E often draws the kerchief, hands, and feet in plausible locations.a professional high quality illustration of a giraffe turtle chimera. a giraffe imitating a turtle. a giraffe made of turtle.Text PromptAI generated imagesWe find that DALLÂ·E is sometimes able to combine distinct animals in plausible ways. We include âpikachuâ to explore DALLÂ·Eâs ability to incorporate knowledge of popular media, and ârobotâ to explore its ability to generate animal cyborgs. Generally, the features of the second animal mentioned in the caption tend to be dominant.We also find that inserting the phrase âprofessional high qualityâ before âillustrationâ and âemojiâ sometimes improves the quality and consistency of the results.a professional high quality emoji of a lovestruck cup of bobaText PromptAI generated imagesWe find that DALLÂ·E is sometimes able to combine distinct animals in plausible ways. We include âpikachuâ to explore DALLÂ·Eâs ability to incorporate knowledge of popular media, and ârobotâ to explore its ability to generate animal cyborgs. Generally, the features of the second animal mentioned in the caption tend to be dominant.We also find that inserting the phrase âprofessional high qualityâ before âillustrationâ and âemojiâ sometimes improves the quality and consistency of the results.Zero-shot visual reasoningGPT-3 can be instructed to perform many kinds of tasks solely from a description and a cue to generate the answer supplied in its prompt, without any additional training. For example, when prompted with the phrase âhere is the sentence âa person walking his dog in the parkâ translated into French:â, GPT-3 answers âun homme qui promÃ¨ne son chien dans le parc.â This capability is calledÂ zero-shot reasoning.Â We find that DALLÂ·E extends this capability to the visual domain, and is able to perform several kinds of image-to-image translation tasks when prompted in the rightÂ way.the exact same cat on the top as a sketch on the bottomText PromptImage PromptAI generated imagesWe find that DALLÂ·E is able to apply several kinds of image transformations to photos of animals, with varying degrees of reliability. The most straightforward ones, such as âphoto colored pinkâ and âphoto reflected upside-down,â also tend to be the most reliable, although the photo is often not copied or reflected exactly. The transformation âanimal in extreme close-up viewâ requires DALLÂ·E to recognize the breed of the animal in the photo, and render it up close with the appropriate details. This works less reliably, and for several of the photos, DALLÂ·E only generates plausible completions in one or two instances.Other transformations, such as âanimal with sunglassesâ and âanimal wearing a bow tie,â require placing the accessory on the correct part of the animalâs body. Those that only change the color of the animal, such as âanimal colored pink,â are less reliable, but show that DALLÂ·E is sometimes capable of segmenting the animal from the background. Finally, the transformations âa sketch of the animalâ and âa cell phone case with the animalâ explore the use of this capability for illustrations and product design.the exact same teapot on the top with âgptâ written on it on the bottomText PromptImage PromptAI generated imagesWe find that DALLÂ·E is able to apply several different kinds of image transformations to photos of teapots, with varying degrees of reliability. Aside from being able to modify the color of the teapot (e.g., âcolored blueâ) or its pattern (e.g., âwith stripesâ), DALLÂ·E can also render text (e.g., âwith âgptâ written on itâ) and map the letters onto the curved surface of the teapot in a plausible way. With much less reliability, it can also draw the teapot in a smaller size (for the âtinyâ option) and in a broken state (for the âbrokenâ option).We did not anticipate that this capability would emerge, and made no modifications to the neural network or training procedure to encourage it. Motivated by these results, we measure DALLÂ·Eâs aptitude for analogical reasoning problems by testing it on Ravenâs progressive matrices, a visual IQ test that saw widespread use in the 20thÂ century.a sequence of geometric shapes.Text PromptImage PromptAI generated imagesRather than treating the IQ test a multiple-choice problem as originally intended, we ask DALLÂ·E to complete the bottom-right corner of each image using argmax sampling, and consider its completion to be correct if it is a close visual match to the original.DALLÂ·E is often able to solve matrices that involve continuing simple patterns or basic geometric reasoning, such as those in sets B and C. It is sometimes able to solve matrices that involve recognizing permutations and applying boolean operations, such as those in set D. The instances in set E tend to be the most difficult, and DALLÂ·E gets almost none of them correct.For each of the sets, we measure DALLÂ·Eâs performance on both the original images, and the images with the colors inverted. The inversion of colors should pose no additional difficulty for a human, yet does generally impair DALLÂ·Eâs performance, suggesting its capabilities may be brittle in unexpected ways.Geographic knowledgeWe find that DALLÂ·E has learned about geographic facts, landmarks, and neighborhoods. Its knowledge of these concepts is surprisingly precise in some ways and flawed inÂ others.a photo of the food of chinaText PromptAI generated imagesWe test DALLÂ·Eâs understanding of simple geographical facts, such as country flags, cuisines, and local wildlife. While DALLÂ·E successfully answers many of these queries, such as those involving national flags, it often reflects superficial stereotypes for choices like âfoodâ and âwildlife,â as opposed to representing the full diversity encountered in the real world.a photo of alamo square, san francisco, from a street at nightText PromptAI generated imagesWe find that DALLÂ·E is sometimes capable of rendering semblances of certain locations in San Francisco. For locations familiar to the authors, such as San Francisco, they evoke a sense of dÃ©jÃ  vuâeerie simulacra of streets, sidewalks and cafes that remind us of very specific locations that do not exist.a photo of san franciscoâs golden gate bridgeText PromptImage PromptAI generated imagesWe can also prompt DALLÂ·E to draw famous landmarks. In fact, we can even dictate when the photo was taken by specifying the first few rows of the sky. When the sky is dark, for example, DALLÂ·E recognizes it is night, and turns on the lights in the buildings.Temporal knowledgeIn addition to exploring DALLÂ·Eâs knowledge of concepts that vary over space, we also explore its knowledge of concepts that vary overÂ time.a photo of a phone from the 20sText PromptImage PromptAI generated imagesWe find that DALLÂ·E has learned about basic stereotypical trends in design and technology over the decades. Technological artifacts appear to go through periods of explosion of change, dramatically shifting for a decade or two, then changing more incrementally, becoming refined and streamlined.  Summary of approach and prior workDALLÂ·E is a simple decoder-only transformer that receives both the text and the image as a single stream of 1280 tokensâ256 for the text and 1024 for the imageâand models all of them autoregressively. The attention mask at each of its 64 self-attention layers allows each image token to attend to all text tokens. DALLÂ·E uses the standard causal mask for the text tokens, and sparse attention for the image tokens with either a row, column, or convolutional attention pattern, depending on the layer. We provide more details about the architecture and training procedure in ourÂ paper.Text-to-image synthesis has been an active area of research since the pioneering work of Reed et. al,[^reference-1]Â whose approach uses a GAN conditioned on text embeddings. The embeddings are produced by an encoder pretrained using a contrastive loss, not unlike CLIP. StackGAN[^reference-3]Â and StackGAN++[^reference-4]Â use multi-scale GANs to scale up the image resolution and improve visual fidelity. AttnGAN[^reference-5]Â incorporates attention between the text and image features, and proposes a contrastive text-image feature matching loss as an auxiliary objective. This is interesting to compare to our reranking with CLIP, which is done offline. Other work[^reference-2][^reference-6][^reference-7] incorporates additional sources of supervision during training to improve image quality. Finally, work by Nguyen et. al[^reference-8]Â and Cho et. al[^reference-9]Â explores sampling-based strategies for image generation that leverage pretrained multimodal discriminativeÂ models.Similar to the rejection sampling used inÂ VQVAE-2, we useÂ CLIPÂ to rerank the top 32 of 512 samples for each caption in all of the interactive visuals. This procedure can also be seen as a kind of language-guided search[^reference-16], and can have a dramatic impact on sampleÂ quality.an illustration of a baby daikon radish in a tutu walking a dog [caption 1, best 8 of 2048]Text PromptAI generated imagesReranking the samples from DALLÂ·E using CLIP can dramatically improve consistency and quality of the samples.AuthorsPrimary AuthorsAditya RameshMikhail PavlovGabriel GohScott GraySupporting AuthorsMark ChenRewon ChildVedant MisraPamela MishkinGretchen KruegerSandhini AgarwalIlya SutskeverResearchOverviewIndexProductOverviewChatGPTGPT-4DALLÂ·E 2Customer storiesSafety standardsAPI data privacyPricingSafetyOverviewCompanyAboutBlogCareersCharterSecurityOpenAI Â© 2015âââ2023Terms & policiesPrivacy policyBrand guidelinesSocialTwitterYouTubeGitHubSoundCloudLinkedInBack to top
