


Insights from global conversations












CloseSearch Submit Skip to main contentSite NavigationResearchOverviewIndexProductOverviewChatGPTGPT-4DALLÂ·E 2Customer storiesSafety standardsAPI data privacyPricingDevelopersOverviewDocumentationAPI referenceExamplesSafetyCompanyAboutBlogCareersCharterSecuritySearch Navigation quick links Log inSign upMenu Mobile Navigation CloseSite NavigationResearchProductDevelopersSafetyCompany Quick Links Log inSign upSearch Submit Insights from global conversationsWe are sharing what we learned from our conversations across 22 countries, and how we will be incorporating those insights moving forward.Photo: Tom IsaacsonJune 29, 2023AuthorsOpenAI Announcements,Â Responsible AI,Â CommunityWe know that in order to fulfill our mission to build AI systems that benefit everyone, we need to spend significant time directly engaging people who are interacting with and affected by our technology. This is why, for four weeks in May and June, an OpenAI team led by our CEO Sam Altman traveled to 25 cities across 6 continents to speak with users, developers, policymakers, and the public, and hear about each communityâs priorities for AI development and deployment. We are deeply grateful to the hosts and partners who helped make our trip a success.Photo: Tom IsaacsonWhat we learnedOur users and developers are already building valuable applications.We were inspired by the creativity and resourcefulness we saw on the trip. In Nigeria, high school students told us how they used ChatGPT to help break down complicated study topics. In Singapore, civil servants are incorporating OpenAI tools to provide public services more efficiently. In France, a grocery chain is using our tools to help customers reduce food waste and developers are using our tools to make code more efficient and secure. (Weâre eager to hear more about how our services are making an impactâif youâve got a story you think we should know about, please contact us.)There are common hopes and concerns for AIâs impact among communities. Many people shared their enthusiasm for the promise of the tools to expand and improve access to personalized education and healthcare, boost economic growth, and enable professionals across the board to reduce administrative tasks and focus on the highest-impact aspects of their work. Thereâs growing demand for code and services around the world, and more natural user interfaces can reduce literacy barriers and expand access to services. At the same time, many people we spoke to raised concerns related to misinformation, economic displacement, and safety and security risks of increasingly powerful models.Policymakers everywhere are deeply engaged on AI. Policymakers are focused on ensuring safe and beneficial deployment of current tools, and serious about addressing the positive potential as well as the risks of future models. We sat down with dozens of senior policymakers and heads of state around the globe to understand their approach to the rapid adoption of large AI models. What we heard was remarkably consistent: leaders want to maximize the benefit of this new technology for their citizens while putting in place appropriate guardrails to manage its risks, both those from the technology that exists today and those we expect to emerge as the technology becomes more powerful. The policymakers we spoke with want ongoing dialogue with, and safety commitments from, leading AI labs to be a key element of their approach, and are supportive of exploring a global framework to manage powerful future AI systems.People want to know more about our core values.The trip allowed us to reinforce our intentions. For example, one common question was on our use of customer data, giving us an opportunity to reiterate that we do not train on API customer data, and that ChatGPT users can easily opt-out as well. We also had a chance to share that we have always been focused on building thoughtful safety mechanismsânot only for AGI, but also for the AI products weâre shipping today. We will continue to invest deeply into making current systems safe before they are released and into improving them based on user feedback.Photo: Tom IsaacsonWhatâs nextThe trip has helped us better understand the perspectives of users, developers, and government leaders around the world. With their feedback in mind, we are placing additional focus on these areas:Making our products more useful, impactful, and accessible. The trip clarified our sense of what it takes for our products to be accessible and useful for users and developers around the world. We are working on changes to make it easier for people to guide our models toward responses that reflect a wider variety of individual needs and local cultures and contexts. We are also working toward better performance for languages other than English, considering not only lab benchmarks, but also how accurately and efficiently our models perform in the real-world deployment scenarios that matter most to our developers. And we are committed to continuing to make our pricing structure accessible for developers around the world.Further developing best practices for governing highly capable foundation models. As the public debate over new AI laws and regulations continues, we will redouble our efforts to pilot and refine concrete governance practices specifically tailored to highly capable foundation models like the ones that we produce. This includes critical safety work streams such as pre-deployment safety evaluation and adversarial testing, and new efforts to empower people to track the provenance of AI-generated content. Such measures will, we believe, be important components of a governance ecosystem for AI, alongside long-established laws and sector-specific policies for some important applications. We will also continue to invest in piloting broad-based public input approaches into our deployment decisions, adding in localization features to our systems, and fostering an international research community to expand and strengthen the evaluation of model capabilities and risks, including via external research on our AI systems and our cybersecurity grants program.Working to unlock AIâs benefits. We will be expanding our efforts to support broad AI literacy, which we heard is a priority for many communities, as well as investing in ways for creators, publishers and content producers to benefit from these new technologies so we can continue to have a healthy digital ecosystem. Additionally, we are building teams that can provide more support to organizations that are exploring how to use our tools for broadly beneficial applications, and conducting research into and policy recommendations for the social and economic implications of the systems we build.We will have more to say in the weeks and months ahead in each of these areas. A warm thank you to everyone around the world who shared their perspectives and experiences with us.Photo: Tom IsaacsonAuthorsOpenAI View all articlesResearchOverviewIndexProductOverviewChatGPTGPT-4DALLÂ·E 2Customer storiesSafety standardsAPI data privacyPricingSafetyOverviewCompanyAboutBlogCareersCharterSecurityOpenAI Â© 2015âââ2023Terms & policiesPrivacy policyBrand guidelinesSocialTwitterYouTubeGitHubSoundCloudLinkedInBack to top
