


DALL·E 2












CloseSearch Submit Skip to main contentSite NavigationResearchOverviewIndexProductOverviewChatGPTGPT-4DALLÂ·E 2Customer storiesSafety standardsAPI data privacyPricingDevelopersOverviewDocumentationAPI referenceExamplesSafetyCompanyAboutBlogCareersCharterSecuritySearch Navigation quick links Log inSign upMenu Mobile Navigation CloseSite NavigationResearchProductDevelopersSafetyCompany Quick Links Log inSign upSearch Submit DALLÂ·E 2DALLÂ·E 2 is an AI system that can create realistic images and art from a description in natural language.Quick linksTry DALLÂ·EFollow on InstagramDALLÂ·E 2 explained2:47Latest updatesView all updatesDALLÂ·E API now available in public betaNov 3, 2022November 3, 2022DALLÂ·E 2: Extending creativityJul 14, 2022July 14, 2022DALLÂ·E now available without waitlistSep 28, 2022September 28, 2022DALLÂ·E: Introducing outpaintingAug 31, 2022August 31, 2022DALLÂ·E 2 can create original, realistic images and art from a text description. It can combine concepts, attributes, and styles.TabsImage generationOutpaintingInpaintingVariationsDALLÂ·E 2 can create original, realistic images and art from a text description. It can combine concepts, attributes, and styles.Try DALLÂ·EInputAn astronaut riding a horse in photorealistic style.OutputOutputOutput NavigationGo to slide 1Go to slide 2Go to slide 3Go to slide 4Go to slide 5DALLÂ·E 2 can expand images beyond whatâs in the original canvas, creating expansive new compositions.Try DALLÂ·EInputOutputDALLÂ·E 2 can make realistic edits to existing images from a natural language caption. It can add and remove elements while taking shadows, reflections, and textures into account.Try DALLÂ·EInputAdd a flamingo beside the pool.OutputOutputOutput NavigationGo to slide 1Go to slide 2Go to slide 3Go to slide 4Go to slide 5DALLÂ·E 2 can take an image and create different variations of it inspired by the original.Try DALLÂ·EInputOutputOutputOutput NavigationGo to slide 1Go to slide 2Go to slide 3Go to slide 4Go to slide 5In January 2021, OpenAI introduced DALLÂ·E. One year later, our newest system, DALLÂ·E 2, generates more realistic and accurate images with 4x greater resolution.DALLÂ·E 1DALLÂ·E 2DALLÂ·E 2 is preferred over DALLÂ·E 1 when evaluators compared each model.71.7%preferred for caption matching88.8%preferred for photorealismRelated researchView all researchHierarchical text-conditional image generation with CLIP latentsApr 13, 2022April 13, 2022DALLÂ·E: Creating images from textJan 5, 2021January 5, 2021DALLÂ·E 2 pre-training mitigationsJun 28, 2022June 28, 2022CLIP: Connecting text and imagesJan 5, 2021January 5, 2021A focus on safetyDALLÂ·E 2 began as a research project and is now available in beta. Safety mitigations we have developed and continue to improve upon include:Preventing harmful generationsWeâve limited the ability for DALLÂ·E 2 to generate violent, hate, or adult images. By removing the most explicit content from the training data, we minimized DALLÂ·E 2âs exposure to these concepts. We also used advanced techniques to prevent photorealistic generations of real individualsâ faces, including those of public figures.Read about improving safetyCurbing misuseOur content policy does not allow users to generate violent, adult, or political content, among other categories. We wonât generate images if our filters identify text prompts and image uploads that may violate our policies. We also have automated and human monitoring systems to guard against misuse.Read content policyPhased deployment based on learningLearning from real-world use is an important part of developing and deploying AI responsibly. We began by previewing DALLÂ·E 2 to a limited number of trusted users. As we learned more about the technologyâs capabilities and limitations, and gained confidence in our safety systems, we slowly added more users and made DALLÂ·E available in beta in July 2022.View risks and limitationsOur hope is that DALLÂ·E 2 will empower people to express themselves creatively. DALLÂ·E 2 also helps us understand how advanced AI systems see and understand our world, which is critical to our mission of creating AI that benefits humanity.CreditsResearch AdvancementsAditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, Mark ChenEngineering, Design, Product, and PrototypingJeff Belgum, Dave Cummings, Jonathan Gordon, Chris Hallacy, Shawn Jain, Joanne Jang, Fraser Kelton, Vishal Kuo, Joel Lehman, Rachel Lim, Bianca Martin, Evan Morikawa, Rajeev Nayak, Glenn Powell, Krijn Rijshouwer, David Schnurr, Maddie Simens, Kenneth Stanley, Felipe Such, Chelsea Voss, Justin Jay WangComms, Policy, Legal, Ops, Safety, and SecuritySteven Adler, Lama Ahmad, Miles Brundage, Kevin Button, Che Chang, Fotis Chantzis, Derek Chen, Frances Choi, Steve Dowling, Elie Georges, Shino Jomoto, Aris Konstantinidis, Gretchen Krueger, Andrew Mayne, Pamela Mishkin, Bob Rotsted, Natalie Summers, Dave Willner, Hannah WongAcknowledgmentsThanks to those who helped with and provided feedback on this release: Sandhini Agarwal, Sam Altman, Chester Cho, Peter Hoeschele, Jacob Jackson, Jong Wook Kim, Matt Knight, Jason Kwon, Anna Makanju, Katie Mayer, Bob McGrew, Luke Miller, Mira Murati, Adam Nace, Hyeonwoo Noh, Cullen OâKeefe, Long Ouyang, Michael Petrov, Henrique Ponde de Oliveira Pinto, Alec Radford, Girish Sastry, Pranav Shyam, Aravind Srinivas, Ilya Sutskever, Preston Tuggle, Arun Vijayvergiya, Peter WelinderResearchOverviewIndexProductOverviewChatGPTGPT-4DALLÂ·E 2Customer storiesSafety standardsAPI data privacyPricingSafetyOverviewCompanyAboutBlogCareersCharterSecurityOpenAI Â© 2015âââ2023Terms & policiesPrivacy policyBrand guidelinesSocialTwitterYouTubeGitHubSoundCloudLinkedInBack to top
