


OpenAI API












CloseSearch Submit Skip to main contentSite NavigationResearchOverviewIndexProductOverviewChatGPTGPT-4DALLÂ·E 2Customer storiesSafety standardsAPI data privacyPricingDevelopersOverviewDocumentationAPI referenceExamplesSafetyCompanyAboutBlogCareersCharterSecuritySearch Navigation quick links Log inSign upMenu Mobile Navigation CloseSite NavigationResearchProductDevelopersSafetyCompany Quick Links Log inSign upSearch Submit OpenAI APIWeâre releasing an API for accessing new AI models developed by OpenAI.Quick linksSign upExplore the APIIllustration: Ruby ChenJune 11, 2020AuthorsGreg BrockmanMira MuratiPeter WelinderOpenAI Announcements,Â ProductWeâre releasing an API for accessing new AI models developed by OpenAI. Unlike most AI systems which are designed for one use-case, the API today provides a general-purpose âtext in, text outâ interface, allowing users to try it on virtually any English language task. You can now request access in order to integrate the API into your product, develop an entirely new application, or help us explore the strengths and limits of this technology.Given any text prompt, the API will return a text completion, attempting to match the pattern you gave it. You can âprogramâ it by showing it just a few examples of what youâd like it to do; its success generally varies depending on how complex the task is. The API also allows you to hone performance on specific tasks by training on a dataset (small or large) of examples you provide, or by learning from human feedback provided by users orÂ labelers.Weâve designed the API to be both simple for anyone to use but also flexible enough to make machine learning teams more productive. In fact, many of our teams are now using the API so that they can focus on machine learning research rather than distributed systems problems. Today the API runs models with weights from theÂ GPT-3Â family with many speed and throughput improvements. Machine learning is moving very fast, and weâre constantly upgrading our technology so that our users stay up toÂ date.The fieldâs pace of progress means that there are frequently surprising new applications of AI, both positive and negative. We will terminate API access for obviously harmful use-cases, such as harassment, spam, radicalization, or astroturfing. But we also know we canât anticipate all of the possible consequences of this technology, so we are launching today in a private beta rather than general availability, building tools to help users better control the content our API returns, and researching safety-relevant aspects of language technology (such as analyzing, mitigating, and intervening on harmful bias). Weâll share what we learn so that our users and the broader community can build more human-positive AIÂ systems.In addition to being a revenue source to help usÂ cover costsÂ in pursuit ofÂ our mission, the API has pushed us to sharpen our focus on general-purpose AI technologyâadvancing the technology, making it usable, and considering its impacts in the real world. We hope that the API will greatly lower theÂ barrierÂ to producing beneficial AI-powered products, resulting in tools and services that are hard to imagineÂ today.Interested in exploring the API? Join companies likeÂ Algolia,Â Quizlet, andÂ Reddit, and researchers at institutions like theÂ Middlebury InstituteÂ in ourÂ privateÂ beta.Join our Applied AI teamFrequently asked questionsWhy did OpenAI decide to release a commercial product?Ultimately, what weÂ care about mostÂ is ensuring artificial general intelligence benefits everyone. We see developing commercial products as one of the ways to make sure we have enough funding toÂ succeed.We also believe that safely deploying powerful AI systems in the world will be hard to get right. In releasing the API, we are working closely with our partners to see what challenges arise when AI systems are used in the real world. This will help guide our efforts to understand how deploying future AI systems will go, and what we need to do to make sure they are safe and beneficial forÂ everyone.Why did OpenAI choose to release an API instead of open-sourcing the models?There are three main reasons we did this. First, commercializing the technology helps us pay for our ongoing AI research, safety, and policyÂ efforts.Second, many of the models underlying the API are very large, taking a lot of expertise to develop and deploy and making them very expensive to run. This makes it hard for anyone except larger companies to benefit from the underlying technology. Weâre hopeful that the API will make powerful AI systems more accessible to smaller businesses andÂ organizations.Third, the API model allows us to more easily respond to misuse of the technology. Since it is hard to predict the downstream use cases of our models, it feels inherently safer to release them via an API and broaden access over time, rather than release an open source model where access cannot be adjusted if it turns out to have harmfulÂ applications.What specifically will OpenAI do about misuse of the API, given what youâve previously said about GPT-2?With GPT-2, one of our key concerns was malicious use of the model (e.g., for disinformation), which is difficult to prevent once a model is open sourced. For the API, weâre able to better prevent misuse by limiting access to approved customers and use cases. We have a mandatory production review process before proposed applications can go live. In production reviews, we evaluate applications across a few axes, asking questions like:Â Is this a currently supported use case?,Â How open-ended is the application?,Â How risky is the application?,Â How do you plan to address potential misuse?, andÂ Who are the end users of yourÂ application?.We terminate API access for use cases that are found to cause (or are intended to cause) physical, emotional, or psychological harm to people, including but not limited to harassment, intentional deception, radicalization, astroturfing, or spam, as well as applications that have insufficient guardrails to limit misuse by end users. As we gain more experience operating the API in practice, we will continually refine the categories of use we are able to support, both to broaden the range of applications we can support, and to create finer-grained categories for those we have misuse concernsÂ about.One key factor we consider in approving uses of the API is the extent to which an application exhibits open-ended versus constrained behavior with regard to the underlying generative capabilities of the system. Open-ended applications of the API (i.e., ones that enable frictionless generation of large amounts of customizable text via arbitrary prompts) are especially susceptible to misuse. Constraints that can make generative use cases safer include systems design that keeps a human in the loop, end user access restrictions, post-processing of outputs, content filtration, input/output length limitations, active monitoring, and topicalityÂ limitations.We are also continuing to conduct research into the potential misuses of models served by the API, including with third-party researchers via ourÂ academic access program. Weâre starting with a very limited number of researchers at this time and already have some results from our academic partners atÂ Middlebury Institute,Â University of Washington, and Allen Institute for AI. We have tens of thousands of applicants for this program already and are currently prioritizing applications focused on fairness and representationÂ research.How will OpenAI mitigate harmful bias and other negative effects of models served by the API?Mitigating negative effects such as harmful bias is a hard, industry-wide issue that is extremely important. As we discuss in theÂ GPT-3 paperÂ andÂ model card, our API models do exhibit biases that will be reflected in generated text. Here are the steps weâre taking to address theseÂ issues:Weâve developed usage guidelines that help developers understand and address potential safetyÂ issues.Weâre working closely with users to understand their use cases and develop tools to surface and intervene to mitigate harmfulÂ bias.Weâre conducting our own research into manifestations of harmful bias and broader issues in fairness and representation, which will help inform our work via improved documentation of existing models as well as various improvements to futureÂ models.We recognize that bias is a problem that manifests at the intersection of a system and a deployed context; applications built with our technology are sociotechnical systems, so we work with our developers to ensure theyâre putting in appropriate processes and human-in-the-loop systems to monitor for adverseÂ behavior.Our goal is to continue to develop our understanding of the APIâs potential harms in each context of use, and continually improve our tools and processes to help minimizeÂ them.Updated September 18,Â 2020AuthorsGreg BrockmanView all articlesMira MuratiView all articlesPeter WelinderView all articlesOpenAI View all articlesResearchOverviewIndexProductOverviewChatGPTGPT-4DALLÂ·E 2Customer storiesSafety standardsAPI data privacyPricingSafetyOverviewCompanyAboutBlogCareersCharterSecurityOpenAI Â© 2015âââ2023Terms & policiesPrivacy policyBrand guidelinesSocialTwitterYouTubeGitHubSoundCloudLinkedInBack to top
