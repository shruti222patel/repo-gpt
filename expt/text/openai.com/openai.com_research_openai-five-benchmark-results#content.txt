


OpenAI Five Benchmark: Results













CloseSearch Submit Skip to main contentSite NavigationResearchOverviewIndexProductOverviewChatGPTGPT-4DALLÂ·E 2Customer storiesSafety standardsAPI data privacyPricingDevelopersOverviewDocumentationAPI referenceExamplesSafetyCompanyAboutBlogCareersCharterSecuritySearch Navigation quick links Log inSign upMenu Mobile Navigation CloseSite NavigationResearchProductDevelopersSafetyCompany Quick Links Log inSign upSearch Submit OpenAI Five Benchmark: ResultsYesterday,Â OpenAI FiveÂ won a best-of-three against a team of 99.95th percentile Dota players:Â Blitz,Â Cap,Â Fogged,Â Merlini, andÂ MoonMeanderâfour of whom have played Dota professionallyâin front of a live audience and 100,000 concurrent livestreamÂ viewers.August 6, 2018Dota 2,Â Reinforcement learning,Â Games,Â Software engineering,Â Self-play,Â OpenAI FiveThe human team won game three after the audience adversarially selected Fiveâs heroes. We also showed our preliminary work to introspect Fiveâs view of the game, including its probability of winning, which made predictions surprising to the human observers. These results show that Five is a step towards advanced AI systems which can handle the complexity and uncertainty of theÂ realÂ world.In case you missed it: the livestream from the Benchmark commentated byÂ PurgeÂ andÂ ODPixel.Â ChristyÂ andÂ GregÂ also both livetweeted theÂ event.Overview of the dayAudience gameThe day began with a team of volunteers from the audience bravely playing the first public match against OpenAIÂ Five. Five won within the first 14 minutes (an evenly-matched game generally takes 45Â minutes).Games 1 and 2We revealed a new OpenAI Five capabilityâthe ability toÂ draft. Drafting is considered anÂ extremely challengingÂ part of Dota, since heroes interact with each other in complexÂ ways.In late June we added a win probability output to our neural network to introspect what OpenAI Five is predicting. When later considering drafting, we realized we could use this to evaluate the win probability of any draft: just look at the prediction on the first frame of a game with that lineup. In one week of implementation, we crafted a fake frame for each of the 11 million possible team matchups and wrote a tree search to find OpenAI Fiveâs optimalÂ draft.After the game 1 draft, OpenAI Five predicted a 95% win probability, even though the matchup seemed about even to the human observers. It won the first game in 21 minutes and 37 seconds. After the game 2 draft, OpenAI Five predicted a 76.2% win probability, and won the second in 24 minutes and 53Â seconds.Game 3: audience draftFor the third game, we asked the audience to draft OpenAI Fiveâs heroes. AsÂ expected, they selected an adversarialÂ lineup.The line-up for OAI5 this round is fairly Looney-Tunes. Two big scary tanks, Sven and Axe, with two good invisibility / ganker (surprise attack) heroes, Slark and Riki, and the Queen of Pain who can blink (teleport a few metres) for escape and attack.— Smerity (@Smerity) August 5, 2018 Before the game began, OpenAI Five predicted a 2.9% chance of winning. Five played on despite the bad odds, and at one point made enough progress to predict a 17% win probability, before ultimately losing after 35 minutes and 47Â seconds.TrainingOur usual development cycle is to train each major revision of the system from scratch. However, this version of OpenAI Five contains parameters that have been training since June 9th across six major system revisions. Each revision was initialized with parameters from the previousÂ one.We invested heavily in âsurgeryâ tooling which allows us to map old parameters to a new network architecture. For example, when we first trained warding, we shared a single action head for determining where to move and where to place a ward. But Five would often drop wards seemingly in the direction it was trying to go, and we hypothesized it was allocating its capacity primarily to movement. Our tooling let us split the head into two clones initialized with the sameÂ parameters.We estimate that we used the following amounts ofÂ computeÂ to train our various DotaÂ systems:1v1 model: 8Â petaflop/s-daysJune 6th model: 11 petaflop/s-days[^footnote-revision]Aug 5th model: 35 petaflop/s-days[^footnote-revision]We are also releasing our latestÂ networkÂ architecture.Peaking at the modelWe can get some insight into the modelâs planning via an output which predicts where a hero will be in the future. In the following video, the highlighted boxes show the predicted location of Sven in 6Â seconds:OpenAI Five planning ahead5:27We can also train outputs to predict various other quantities â last hits, tower counts, and theÂ like:OpenAI Five predicting the game7:37Making our model function requires working through many bugs and unexpected behaviors. Here are someÂ examples:OpenAI Five growing pains3:20Whatâs nextThese results give us confidence in moving to the next phase of this project: playing a team of professionals at The International later this month. We will announce details of the games once they are confirmedâfollow usÂ on Twitter to stay up toÂ date!AuthorsOpenAI ResearchOverviewIndexProductOverviewChatGPTGPT-4DALLÂ·E 2Customer storiesSafety standardsAPI data privacyPricingSafetyOverviewCompanyAboutBlogCareersCharterSecurityOpenAI Â© 2015âââ2023Terms & policiesPrivacy policyBrand guidelinesSocialTwitterYouTubeGitHubSoundCloudLinkedInBack to top
