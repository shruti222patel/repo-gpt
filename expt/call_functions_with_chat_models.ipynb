{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64c85e26",
   "metadata": {},
   "source": [
    "## How to generate function arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e71f33",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install scipy\n",
    "!pip install tenacity\n",
    "!pip install tiktoken\n",
    "!pip install termcolor \n",
    "!pip install openai\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dab872c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "import requests\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from termcolor import colored\n",
    "\n",
    "GPT_MODEL = \"gpt-3.5-turbo-0613\"\n",
    "openai_key = \"\"\n",
    "openai.api_key = openai_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d567ddf6-98b8-4270-b602-d2ca86faffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f75fcf7-ba08-4c4b-8602-6042122b302a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\n",
      "Searching the codebase for: test file for file handler\n",
      "Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\n",
      "Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\n",
      "Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\n",
      "Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\n",
      "Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\n",
      "Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'- Create a new file named `test_generic_code_file_handler.py` in the `test/file_handler` directory.\\n- Import the necessary modules and classes for testing.\\n- Write unit tests to verify the functionality of the `GenericCodeFileHandler` class.\\n- Execute the tests and ensure that they pass.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from repo_gpt.agents.repo_comprehender import RepoUnderstandingAgent\n",
    "from repo_gpt.agents.base_agent import BaseAgent\n",
    "from repo_gpt.agents.simple_memory_store import MemoryStore\n",
    "from repo_gpt.logging_config import configure_logging\n",
    "import logging\n",
    "\n",
    "configure_logging(logging.INFO)\n",
    "root_path = Path(\"/Users/shrutipatel/projects/work/repo-gpt/\")\n",
    "repo_agent = RepoUnderstandingAgent(\"Where should I add tests for the new file handler I'm writing? Do I need to create a new test file? If so, where?\",\n",
    "                                    root_path,\n",
    "                                   openai_key = openai_key,\n",
    "                                   debug=True)\n",
    "plan = repo_agent.process_messages()\n",
    "plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418c4e61-0fa5-4268-a422-1ff624b97994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0b9161-405a-4235-911e-9179791e8cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from repo_gpt.agents.code_writer import CodeWritingAgent\n",
    "from repo_gpt.agents.central_intelligence import CentralIntelligenceAgent\n",
    "\n",
    "root_path = Path(\"/Users/shrutipatel/projects/work/repo-gpt/\")\n",
    "embedding_file_path =  root_path / \".repo_gpt/code_embeddings.pkl\"\n",
    "writer_agent = CodeWritingAgent(plan, \n",
    "                                root_path,\n",
    "                                    embedding_file_path,\n",
    "                                   openai_key = openai_key,\n",
    "                                debug=True)\n",
    "result = writer_agent.process_messages()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803418c6-df34-4819-bae3-c3a1d03471a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from repo_gpt.agents.central_intelligence import CentralIntelligenceAgent\n",
    "\n",
    "root_path = Path(\"/Users/shrutipatel/projects/work/repo-gpt/\")\n",
    "embedding_file_path =  root_path / \".repo_gpt/code_embeddings.pkl\"\n",
    "\n",
    "ci_agent = CentralIntelligenceAgent(\"Where should I add tests for the new file handler I'm writing? Do I need to create a new test file? If so, where?\",\n",
    "                                    root_path,\n",
    "                                    embedding_file_path,\n",
    "                                   openai_key = openai_key,\n",
    "                                   debug=True)\n",
    "output = ci_agent.process_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549cdd7a-c762-48ae-b425-a5d15402ea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be1f70a-3419-4432-be55-56dbe035baab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## TODO\n",
    "# - Update initial user query so we include results from semantic search\n",
    "# - Update system prompt and or the function json to include the output schema of the returned code_embedding csv rows\n",
    "# - Update sep for CSV output to a more uncommon character since commas are frequently used in code? (This may not be necessary because converting to csv usually ex\n",
    "# - Add a function where the writeragent can ask the repounderstandingagent\n",
    "# - Update function so you search for files -- this will decrease the token size because we won't send the all the files every time and this will handle larger codebases with greater ease\n",
    "# - Use COD to ensure messages are being compressed while retaining all relevant info\n",
    "# - How can I incorporate reflexion?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
