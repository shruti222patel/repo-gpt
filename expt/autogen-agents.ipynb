{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/microsoft/autogen/blob/main/notebook/agentchat_groupchat_research.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Generated Agent Chat: Performs Research with Multi-Agent Group Chat\n",
    "\n",
    "AutoGen offers conversable agents powered by LLM, tool or human, which can be used to perform tasks collectively via automated chat. This framwork allows tool use and human participance through multi-agent conversation.\n",
    "Please find documentation about this feature [here](https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat).\n",
    "\n",
    "[More useful research paper](https://arxiv.org/pdf/2308.08155.pdf)\n",
    "\n",
    "## Requirements\n",
    "\n",
    "AutoGen requires `Python>=3.8`. To run this notebook example, please install:\n",
    "```bash\n",
    "pip install pyautogen\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "# %pip install pyautogen~=0.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the config list as a JSON string\n",
    "OPENAI_API_KEY = ''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your API Endpoint\n",
    "\n",
    "The [`config_list_from_json`](https://microsoft.github.io/autogen/docs/reference/oai/openai_utils#config_list_from_json) function loads a list of configurations from an environment variable or a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from repo_gpt.file_handler.generic_code_file_handler import PythonFileHandler\n",
    "from repo_gpt.search_service import SearchService, convert_search_df_to_json\n",
    "from pathlib import Path\n",
    "from repo_gpt.openai_service import OpenAIService\n",
    "\n",
    "pythonfilehandler = PythonFileHandler()\n",
    "root_path = Path(\"/Users/shrutipatel/projects/work/repo-gpt/\")\n",
    "embedding_path = root_path / \".repo_gpt/code_embeddings.pkl\"\n",
    "openai_service = OpenAIService(OPENAI_API_KEY)\n",
    "search_service = SearchService(openai_service, embedding_path)\n",
    "        \n",
    "\n",
    "def completed_all_code_updates(code_changes):\n",
    "    return code_changes\n",
    "\n",
    "def create_file(file_path, content):\n",
    "    \"\"\"\n",
    "    Create a new file with the provided content.\n",
    "\n",
    "    Args:\n",
    "    - file_path (str): Path to the new file to be created.\n",
    "    - content (str): Content to write in the new file.\n",
    "\n",
    "    Returns:\n",
    "    - str: Success or error message.\n",
    "    \"\"\"\n",
    "    full_path = root_path / Path(file_path)\n",
    "\n",
    "    # Check if file already exists\n",
    "    if full_path.exists():\n",
    "        return (\n",
    "            f\"File {file_path} already exists. To update it, use append_to_file().\"\n",
    "        )\n",
    "\n",
    "    with open(full_path, \"w\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "    return f\"File {file_path} has been created successfully.\"\n",
    "\n",
    "def append_to_file(file_path, content):\n",
    "    \"\"\"\n",
    "    Append content to an existing file.\n",
    "\n",
    "    Args:\n",
    "    - file_path (str): Path to the file to be updated.\n",
    "    - content (str): Content to append in the file.\n",
    "\n",
    "    Returns:\n",
    "    - str: Success or error message.\n",
    "    \"\"\"\n",
    "    full_path = root_path / Path(file_path)\n",
    "\n",
    "    # Check if file exists\n",
    "    if not full_path.exists():\n",
    "        return f\"File {file_path} does not exist. To create it, use create_file().\"\n",
    "\n",
    "    with open(full_path, \"a\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "    return f\"Content has been appended to {file_path} successfully.\"\n",
    "\n",
    "def view_function_code(function_name):\n",
    "    logger.info(f\"Reading the code for: {function_name}\")\n",
    "    functions_df, classes_df = search_service.find_function_match(\n",
    "        function_name\n",
    "    )\n",
    "\n",
    "    if (classes_df is None or classes_df.empty) and (\n",
    "        functions_df is None or functions_df.empty\n",
    "    ):\n",
    "        return \"\"\n",
    "    elif functions_df is None or functions_df.empty:\n",
    "        return convert_search_df_to_json(classes_df)\n",
    "    elif classes_df is None or classes_df.empty:\n",
    "        return convert_search_df_to_json(functions_df)\n",
    "    else:\n",
    "        return convert_search_df_to_json(functions_df)\n",
    "\n",
    "def semantic_search(query):\n",
    "    logger.info(f\"Searching the codebase for: {query}\")\n",
    "    return convert_search_df_to_json(\n",
    "        search_service.semantic_search_similar_code(query)\n",
    "    )\n",
    "\n",
    "def view_file_functions_and_classes(file_paths):\n",
    "    logger.info(f\"Skimming the code in: {file_paths}\")\n",
    "    results = []\n",
    "    for file_path in file_paths:\n",
    "        full_path = root_path / Path(file_path)\n",
    "\n",
    "        if not full_path.exists():\n",
    "            results.append(f\"File not found: {file_path}\")\n",
    "            continue  # Skip to the next iteration\n",
    "        elif full_path.is_dir():\n",
    "            results.append(\n",
    "                f\"This is not a file, but a directory, pass a filepath instead: {file_path}\"\n",
    "            )\n",
    "            continue  # Skip to the next iteration\n",
    "\n",
    "        # TODO select the correct filehandler and then summarize file\n",
    "        results.append(pythonfilehandler.summarize_file(full_path))\n",
    "\n",
    "    return \"\\n\".join(results)\n",
    "\n",
    "def create_plan_to_complete_user_task(plan):\n",
    "    return plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from repo_gpt.file_handler.generic_code_file_handler import PythonFileHandler\n",
    "from repo_gpt.search_service import SearchService, convert_search_df_to_json\n",
    "from pathlib import Path\n",
    "from repo_gpt.openai_service import OpenAIService\n",
    "\n",
    "pythonfilehandler = PythonFileHandler()\n",
    "root_path = Path(\"/Users/shrutipatel/projects/work/repo-gpt/\")\n",
    "embedding_path = root_path / \".repo_gpt/code_embeddings.pkl\"\n",
    "openai_service = OpenAIService(OPENAI_API_KEY)\n",
    "search_service = SearchService(openai_service, embedding_path)\n",
    "        \n",
    "\n",
    "def completed_all_code_updates(code_changes):\n",
    "    return code_changes\n",
    "\n",
    "def create_file(file_path, content):\n",
    "    \"\"\"\n",
    "    Create a new file with the provided content.\n",
    "\n",
    "    Args:\n",
    "    - file_path (str): Path to the new file to be created.\n",
    "    - content (str): Content to write in the new file.\n",
    "\n",
    "    Returns:\n",
    "    - str: Success or error message.\n",
    "    \"\"\"\n",
    "    full_path = root_path / Path(file_path)\n",
    "\n",
    "    # Check if file already exists\n",
    "    if full_path.exists():\n",
    "        return (\n",
    "            f\"File {file_path} already exists. To update it, use append_to_file().\"\n",
    "        )\n",
    "\n",
    "    with open(full_path, \"w\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "    return f\"File {file_path} has been created successfully.\"\n",
    "\n",
    "def append_to_file(file_path, content):\n",
    "    \"\"\"\n",
    "    Append content to an existing file.\n",
    "\n",
    "    Args:\n",
    "    - file_path (str): Path to the file to be updated.\n",
    "    - content (str): Content to append in the file.\n",
    "\n",
    "    Returns:\n",
    "    - str: Success or error message.\n",
    "    \"\"\"\n",
    "    full_path = root_path / Path(file_path)\n",
    "\n",
    "    # Check if file exists\n",
    "    if not full_path.exists():\n",
    "        return f\"File {file_path} does not exist. To create it, use create_file().\"\n",
    "\n",
    "    with open(full_path, \"a\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "    return f\"Content has been appended to {file_path} successfully.\"\n",
    "\n",
    "def view_function_code(function_name):\n",
    "    logger.info(f\"Reading the code for: {function_name}\")\n",
    "    functions_df, classes_df = search_service.find_function_match(\n",
    "        function_name\n",
    "    )\n",
    "\n",
    "    if (classes_df is None or classes_df.empty) and (\n",
    "        functions_df is None or functions_df.empty\n",
    "    ):\n",
    "        return \"\"\n",
    "    elif functions_df is None or functions_df.empty:\n",
    "        return convert_search_df_to_json(classes_df)\n",
    "    elif classes_df is None or classes_df.empty:\n",
    "        return convert_search_df_to_json(functions_df)\n",
    "    else:\n",
    "        return convert_search_df_to_json(functions_df)\n",
    "\n",
    "def semantic_search(query):\n",
    "    logger.info(f\"Searching the codebase for: {query}\")\n",
    "    return convert_search_df_to_json(\n",
    "        search_service.semantic_search_similar_code(query)\n",
    "    )\n",
    "\n",
    "def view_file_functions_and_classes(file_paths):\n",
    "    logger.info(f\"Skimming the code in: {file_paths}\")\n",
    "    results = []\n",
    "    for file_path in file_paths:\n",
    "        full_path = root_path / Path(file_path)\n",
    "\n",
    "        if not full_path.exists():\n",
    "            results.append(f\"File not found: {file_path}\")\n",
    "            continue  # Skip to the next iteration\n",
    "        elif full_path.is_dir():\n",
    "            results.append(\n",
    "                f\"This is not a file, but a directory, pass a filepath instead: {file_path}\"\n",
    "            )\n",
    "            continue  # Skip to the next iteration\n",
    "\n",
    "        # TODO select the correct filehandler and then summarize file\n",
    "        results.append(pythonfilehandler.summarize_file(full_path))\n",
    "\n",
    "    return \"\\n\".join(results)\n",
    "\n",
    "def create_plan_to_complete_user_task(plan):\n",
    "    return plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "import os\n",
    "import json\n",
    "\n",
    "import tempfile\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "env_var = [\n",
    "{\n",
    "        'model': 'gpt-3.5-turbo',\n",
    "        'api_key': OPENAI_API_KEY,\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-3.5-turbo-16k',\n",
    "        'api_key': OPENAI_API_KEY,\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-4-32k',\n",
    "        'api_key': OPENAI_API_KEY,\n",
    "    },\n",
    "]\n",
    "\n",
    "# Create a temporary file\n",
    "# Write the JSON structure to a temporary file and pass it to config_list_from_json\n",
    "with tempfile.NamedTemporaryFile(mode='w+', delete=True) as temp:\n",
    "    env_var = json.dumps(env_var)\n",
    "    temp.write(env_var)\n",
    "    temp.flush()\n",
    "\n",
    "# OAI_CONFIG_LIST = json.dumps([\n",
    "#     {\n",
    "#         'model': 'gpt-3.5-turbo',\n",
    "#         'api_key': OPENAI_API_KEY,\n",
    "#     },\n",
    "#     {\n",
    "#         'model': 'gpt-3.5-turbo-16k',\n",
    "#         'api_key': OPENAI_API_KEY,\n",
    "#     },\n",
    "#     {\n",
    "#         'model': 'gpt-4-32k',\n",
    "#         'api_key': OPENAI_API_KEY,\n",
    "#     },\n",
    "# ])\n",
    "\n",
    "# Set it as an environment variable\n",
    "# os.environ['OAI_CONFIG'] = OAI_CONFIG_LIST\n",
    "\n",
    "    config_list_gpt4 = autogen.config_list_from_json(\n",
    "        temp.name,\n",
    "        filter_dict={\n",
    "            \"model\": [\"gpt-3.5-turbo\", \"gpt-3.5-turbo-16k\"],\n",
    "        },\n",
    "    )\n",
    "\n",
    "source_code_librarian_config = {\n",
    "    \"functions\": [\n",
    "            {\n",
    "                \"name\": \"semantic_search\",\n",
    "                \"description\": \"Use this function to search the entire codebase semantically. The input should be the search query string.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"query\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": f\"\"\"\n",
    "                            The semantic search query to use to search the code base.\n",
    "                            \"\"\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"query\"],\n",
    "                },\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"view_function_code\",\n",
    "                \"description\": \"Use this function to search for and view a function's code in the user's codebase. Input should be the name of the function you want to search for. An empty response means the given files don't exist.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"function_name\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": f\"\"\"\n",
    "                            The name of the function or its description.\n",
    "                            \"\"\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"function_name\"],\n",
    "                },\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"view_file_functions_and_classes\",\n",
    "                \"description\": \"Use this function to retrieve a list of the functions and classes in a file from the user's codebase. An empty response means the given files don't exist.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"file_paths\": {\n",
    "                            \"type\": \"array\",\n",
    "                            \"items\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"An array of one or more file paths of a file you want to retrieve functions and classes from. If a file doesn't exist, the function will return a string saying so.\",\n",
    "                            },\n",
    "                            \"description\": f\"\"\"\n",
    "                        The file paths of the files you want to retrieve functions and classes for to better understand the user's task. Below are the files within the user's repository:\n",
    "                        {get_relative_path_directory_structure(\"/Users/shrutipatel/projects/work/repo-gpt\")}\n",
    "                        \"\"\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"file_paths\"],\n",
    "                },\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"create_plan_to_complete_user_task\",\n",
    "                \"description\": \"Use this function when you understand the user's task and have a detailed plan ready for completing the user's task. The input should be a step-by-step plan on how to complete the user's task. It can include things like 'Create a new file with a given file path', 'Add the given code to the file', etc.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"plan\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": f\"\"\"\n",
    "                            A step-by-step plan on how to complete the user's task. It can include things like \"Create a new file with a given file path\", \"Add the given code to the file\", etc.\n",
    "                            \"\"\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"plan\"],\n",
    "                },\n",
    "            },\n",
    "        ],\n",
    "    \"config_list\": config_list_gpt4,\n",
    "    \"request_timeout\": 120,\n",
    "}\n",
    "\n",
    "\n",
    "engineer_config = {\n",
    "    \"functions\": [\n",
    "            {\n",
    "                \"name\": \"create_file\",\n",
    "                \"description\": \"Create a new file with the provided content.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"file_path\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Path to the new file to be created.\",\n",
    "                        },\n",
    "                        \"content\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Content to write in the new file.\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"file_path\", \"content\"],\n",
    "                },\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"append_to_file\",\n",
    "                \"description\": \"Append content to an existing file.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"file_path\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Path to the file to be updated.\",\n",
    "                        },\n",
    "                        \"content\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Content to append to the file.\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"file_path\", \"content\"],\n",
    "                },\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"completed_all_code_updates\",\n",
    "                \"description\": \"Call this function when all the code updates are completed.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"code_changes\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Enumeration of all the changes that were made to the code.\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"code_changes\"],\n",
    "                },\n",
    "            },\n",
    "        ],\n",
    "    \"config_list\": config_list_gpt4,\n",
    "    \"request_timeout\": 120,\n",
    "}\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It first looks for environment variable \"OAI_CONFIG_LIST\" which needs to be a valid json string. If that variable is not found, it then looks for a json file named \"OAI_CONFIG_LIST\". It filters the configs by models (you can filter by other keys as well).\n",
    "\n",
    "The config list looks like the following:\n",
    "```python\n",
    "config_list = [\n",
    "    {\n",
    "        'model': 'gpt-4-32k',\n",
    "        'api_key': '<your OpenAI API key here>',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-4-32k',\n",
    "        'api_key': '<your Azure OpenAI API key here>',\n",
    "        'api_base': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-4-32k-0314',\n",
    "        'api_key': '<your Azure OpenAI API key here>',\n",
    "        'api_base': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },\n",
    "]\n",
    "```\n",
    "\n",
    "If you open this notebook in colab, you can upload your files by clicking the file icon on the left panel and then choose \"upload file\" icon.\n",
    "\n",
    "You can set the value of config_list in other ways you prefer, e.g., loading from a YAML file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan\n",
    "1. Create a UseProxyAgent + Assistant for searching the codebase\n",
    "2. If code updates are necessary, generate a detailed plan of next steps\n",
    "3. Engineer + UserProxyAgent writes the code\n",
    "4. Have a Critic + UserProxyAgent that reviews the code (add functions for reading git diffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create simple agent structure\n",
    "[Example Notebook](https://github.com/microsoft/autogen/blob/main/notebook/agentchat_two_users.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_config = {\n",
    "    \"seed\": 42,  # change the seed for different trials\n",
    "    \"temperature\": 0,\n",
    "    \"config_list\": config_list_gpt4,\n",
    "    \"request_timeout\": 120,\n",
    "}\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "   name=\"Admin\",\n",
    "   system_message=\"A human admin. Interact with the planner to discuss the plan. Plan execution needs to be approved by this admin.\",\n",
    "   code_execution_config=False,\n",
    ")\n",
    "engineer = autogen.UserProxyAgent(\n",
    "    name=\"Engineer\",\n",
    "    llm_config=engineer_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    system_message='''Engineer. You follow an approved plan. You write python/shell code to solve tasks. Wrap the code in a code block that specifies the script type. The user can't modify your code. So do not suggest incomplete code which requires others to modify. Don't use a code block if it's not intended to be executed by the executor.\n",
    "Don't include multiple code blocks in one response. Do not ask others to copy and paste the result. Check the execution result returned by the executor.\n",
    "If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.\n",
    "''',\n",
    ")\n",
    "engineer.register_function(\n",
    "    function_map={\n",
    "        \"create_file\": create_file,\n",
    "        \"append_to_file\": append_to_file,\n",
    "        \"completed_all_code_updates\": completed_all_code_updates,\n",
    "    })\n",
    "\n",
    "#\"Repository Manager\" or \"Source Code Librarian\"\n",
    "source_code_librarian = autogen.UserProxyAgent(\n",
    "    name=\"Architect\",\n",
    "    llm_config=source_code_librarian_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    system_message=\"\"\"Architect. You browse the codebase to understand the larger structure, dependencies, metadata, and code logic. \n",
    "Based on your browsing, you answer questions about the code base and create code architecture plans that fit the codebase's existing patterns.\n",
    "You don't write code. You tell the Engineer what to code.\n",
    "    \"\"\"\n",
    ")\n",
    "source_code_librarian.register_function(\n",
    "    function_map={\n",
    "        \"semantic_search\": semantic_search,\n",
    "        \"view_function_code\": view_function_code,\n",
    "        \"view_file_functions_and_classes\": view_file_functions_and_classes,\n",
    "        \"create_plan_to_complete_user_task\": create_plan_to_complete_user_task,\n",
    "    })\n",
    "planner = autogen.AssistantAgent(\n",
    "    name=\"Coordinator\",\n",
    "    system_message='''Coordinator. First, ask for the architect's input and then suggest a plan. \n",
    "The plan may involve an engineer who can write code and an architect who searches the existing codebase.\n",
    "Explain the plan first. Be clear about which step is performed by an engineer, and which is performed by an architect.\n",
    "Revise the plan based on findings from the architect and engineer if necessary.\n",
    "''',\n",
    "    llm_config=gpt4_config,\n",
    ")\n",
    "\n",
    "# TODO replace with test writer\n",
    "executor = autogen.UserProxyAgent(\n",
    "    name=\"Executor\",\n",
    "    system_message=\"Executor. Execute the code written by the engineer and report the result.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "     code_execution_config={\"work_dir\": \"coding\"},\n",
    ")\n",
    "critic = autogen.AssistantAgent(\n",
    "    name=\"Critic\",\n",
    "    system_message=\"Critic. Double check plan, claims, code from other agents and provide feedback. Check whether the plan includes adding verifiable info such as source URL.\",\n",
    "    llm_config=gpt4_config,\n",
    ")\n",
    "# groupchat = autogen.GroupChat(agents=[user_proxy, engineer, source_code_librarian, planner, executor, critic], messages=[], max_round=50)\n",
    "groupchat = autogen.GroupChat(agents=[user_proxy, engineer, source_code_librarian, executor, critic], messages=[], max_round=50)\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=gpt4_config)\n",
    "\n",
    "manager.register_function(\n",
    "        function_map={\n",
    "        \"semantic_search\": semantic_search,\n",
    "        \"view_function_code\": view_function_code,\n",
    "        \"view_file_functions_and_classes\": view_file_functions_and_classes,\n",
    "        \"create_plan_to_complete_user_task\": create_plan_to_complete_user_task,\n",
    "        \"create_file\": create_file,\n",
    "        \"append_to_file\": append_to_file,\n",
    "        \"completed_all_code_updates\": completed_all_code_updates,\n",
    "    })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mAdmin\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "Add a code file handler for Elixir.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mEngineer\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: append_to_file *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"file_path\": \"handlers.json\",\n",
      "  \"content\": \",\\n  \\\"elixir\\\": \\\"elixir_handler.py\\\"\"\n",
      "}\n",
      "\u001b[32m***************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mArchitect\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"append_to_file\" *****\u001b[0m\n",
      "Error: Function append_to_file not found.\n",
      "\u001b[32m***********************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mArchitect\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: view_function_code *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"function_name\": \"append_to_file\"\n",
      "}\n",
      "\u001b[32m*******************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mEngineer\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"view_function_code\" *****\u001b[0m\n",
      "Error: Function view_function_code not found.\n",
      "\u001b[32m***************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "user_proxy.initiate_chat(\n",
    "    manager,\n",
    "    message=\"\"\"\n",
    "Add a code file handler for Elixir.\n",
    "\"\"\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Group Chat without Critic for Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupchat_nocritic = autogen.GroupChat(agents=[user_proxy, engineer, scientist, planner, executor], messages=[], max_round=50)\n",
    "for agent in groupchat.agents:\n",
    "    agent.reset()\n",
    "manager_nocritic = autogen.GroupChatManager(groupchat=groupchat_nocritic, llm_config=gpt4_config)\n",
    "user_proxy.initiate_chat(\n",
    "    manager_nocritic,\n",
    "    message=\"\"\"\n",
    "find papers on LLM applications from arxiv in the last week, create a markdown table of different domains.\n",
    "\"\"\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
